<!DOCTYPE html>
<html lang="zh-CN">





<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content>
  <meta name="author" content="John Doe">
  <meta name="keywords" content>
  <title>论文翻译-使用卷积神经网络图像分类的技巧包-小南</title>

  <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css">


  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.18.1/styles/github-gist.min.css">


<!-- 主题依赖的图标库，不要自行修改 -->
<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">



<link rel="stylesheet" href="/css/main.css">

<!-- 自定义样式保持在最底部 -->


</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>小南</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/back1.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2019-10-18 08:28">
                    星期五, 十月 18日 2019, 8:28 早上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    2.8k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    31
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<blockquote>
<p>本篇博客摘录并翻译一篇论文（未完待续。。。）</p>
</blockquote>
<a id="more"></a>

<h1 id="3-有效训练"><a href="#3-有效训练" class="headerlink" title="3 有效训练"></a>3 有效训练</h1><h2 id="3-1-大批次训练"><a href="#3-1-大批次训练" class="headerlink" title="3.1 大批次训练"></a>3.1 大批次训练</h2><h3 id="线性缩放学习率"><a href="#线性缩放学习率" class="headerlink" title="线性缩放学习率"></a>线性缩放学习率</h3><p>在使用小批次进行随机数据的训练，增加数据批次没有改变随机梯度的期望而减少了方差。换一句话说，一个大批次大小减少梯度的噪音。因此我们可以提高学习率，以沿梯度方向的相反方向获得更大的改进。<strong>特别，如果我们遵循ResNet原论文中的对于批次大小为256时，初始学习率设置成0.1。然后，当改变一个更大的批次大小为b，我们将增加初始学习率为0.1×b/256.</strong></p>
<h3 id="学习率预热"><a href="#学习率预热" class="headerlink" title="学习率预热"></a>学习率预热</h3><p>在训练的开始，所有的参数通常是随机值，因此离最终的解决方案很远。使用过大的学习率可能会导致数值不稳定。在热身启发式中，我们在开始时使用一个小的学习速率，然后在训练过程稳定时切换回初始的学习速率。Goyalet al.[7]提出了一种渐进热身策略，<strong>将学习率从0线性增加到初始学习率。换句话说，假设我们将使用前m个批次（例如5个数据周期）进行预热，并且初始学习率为η，那么在第i批次中，1≤i≤m，我们将学习率设为iη\m。</strong></p>
<h3 id="Zero-gamma"><a href="#Zero-gamma" class="headerlink" title="Zero  gamma"></a>Zero  gamma</h3><p>ResNet结构：一个ResNet网络由多个残差块组成，每个残差块由几个卷积层组成。给定输入x，假设block(x)是block的最后一层的输出，这个残差块将输出x + block(x)。注意，block的最后一层可以是批处理标准化(BN)层。</p>
<p>Batch Normalization：BN层首先标准化其输入，用\(\check{x} \)表示，然后执行一个尺度变换：\({\gamma \check{x} + \beta} \)。γ和β都是可学习的参数，其元素分别初始化为1s和0s。</p>
<p>zero \(\gamma \)技巧：我们对位于残差块末尾的所有BN层初始化γ= 0。 结果：所有残差块仅返回其输入，模拟网络在初始阶段具有较少的层数，更容易训练。</p>
<h3 id="没有bias衰减"><a href="#没有bias衰减" class="headerlink" title="没有bias衰减"></a>没有bias衰减</h3><p>权重衰减（weight decay）：权值衰减通常应用于所有可学习的参数，包括权重和偏差。这相当于对所有参数应用L2正则化，使它们的值趋近于0。</p>
<p>改进：Jia等人指出的只对权重应用正则化，来避免过拟合。</p>
<p>技巧：将权重衰减应用于卷积层和完全连接层中的权重，对偏差不进行衰减。其他参数，包括BN层中的biases以及γ和β，均未调整。</p>
<p>大批次的使用情况：（Large batch training ofconvolutional networks with layer-wise adaptive rate scaling）论文提出分层的自适应学习率，据报告对于超大批量（超过16K）有效。将自身限于能够进行单机训练的情况下，每批不超过2K的批次通常会带来良好的系统效率。</p>
<h2 id="3-2-低精度训练（数值精度类型、数值位数）"><a href="#3-2-低精度训练（数值精度类型、数值位数）" class="headerlink" title="3.2 低精度训练（数值精度类型、数值位数）"></a>3.2 低精度训练（数值精度类型、数值位数）</h2><p>如何加快训练速度：神经网络通常采用32位浮点(FP32)精度进行训练。也就是说，所有的数字都以FP32格式存储，算术运算的输入和输出也是FP32数字。NvidiaV100在FP32中提供14 TFLOPS，但在FP16中提供100 TFLOPS。在V100上从FP32切换到FP16后，整体训练速度提高了2到3倍。（这里根据自己实验设备而定。）</p>
<p>存在的问题：尽管性能有所提高，但降低的精度会缩小范围，使结果更可能超出范围，进而干扰训练进度。</p>
<p>解决方案：（1）Micikeviciusetal建议在FP16中存储所有参数和激活，并使用FP16计算梯度。同时，FP32中的所有参数都有一个副本，用于参数更新。（2）将标量与损失（loss）相乘以更好地将梯度范围对齐到FP16。</p>
<h2 id="3-3-实验结果"><a href="#3-3-实验结果" class="headerlink" title="3.3 实验结果"></a>3.3 实验结果</h2><p><img src="/assets/tricks/table_3.png" srcset="/img/loading.gif" alt="表3.ResNet-50在基线(BS=256, FP32)和更高效的硬件设置(BS=1024, FP16)之间的训练时间和验证精度的比较。"><br><img src="/assets/tricks/table_4.png" srcset="/img/loading.gif" alt="表4. 在ResNet-50上，有效训练中每种启发式方法的分解效果。"></p>
<ul>
<li><p>训练时间减少：与批量大小为256和FP32的基线相比，使用更大的1024批量大小和FP16可以将ResNet-50的训练时间从每个epoch 13.3分钟减少到4.4分钟。</p>
</li>
<li><p>叠加训练技巧提高精度：通过堆叠所有启发式方法进行大批量训练，与基线模型相比，使用1024批大小和FP16训练的模型甚至稍微提高了0.5％的top-1准确性。</p>
</li>
<li><p>实验结果：表4中显示了所有启发式方法的消融研究，仅通过线性缩放学习率将批次大小从256增加到1024会导致top-1准确性降低0.9％，同时堆叠其余三个启发式方法可以弥补这一差距。在训练结束时从FP32切换到FP16不会影响准确性。</p>
</li>
</ul>
<h1 id="4-模型调整"><a href="#4-模型调整" class="headerlink" title="4 模型调整"></a>4 模型调整</h1><h2 id="4-1-ResNet结构"><a href="#4-1-ResNet结构" class="headerlink" title="4.1 ResNet结构"></a>4.1 ResNet结构</h2><p><img src="/assets/tricks/figure_1.png" srcset="/img/loading.gif" alt="图1. ResNet-50网络结构"><br>ResNet网络结构：（如图1所示），ResNet网络由输入主干，四个后续阶段和最终输出层组成。<br>（1）输入主干具有步长为2，输出通道为64，卷积核为7×7的卷积层，紧接着应用步长为2，核为3×3的池化层。输入主干将输入宽度和高度减少4倍，并将其通道大小增加到64。</p>
<p>（2）从阶段2开始，每个阶段都从一个降采样块（down sampling block）开始，然后是几个残差块（residual block）。在下采样块中，有路径A和路径B。</p>
<ul>
<li>路径A有三个卷积层，其卷积核大小分别为1×1,3×3和1×1。第一个卷积的步长为2，可将输入宽度和高度减半；最后一个卷积的输出通道是前两个卷积的输出通道的4倍，这称为瓶颈结构（bottleneck block）。</li>
<li>路径B使用步长为2的1×1卷积将输入形状转换为路径A的输出形状，因此可以将两条路径的输出求和以获得下采样块的输出。</li>
</ul>
<p>（3）残差块类似于下采样块，除了仅使用步长为1的卷积。</p>
<p>（4）可以在每个阶段改变残差块的数量，得到不同的ResNet模型。如ResNet18,ResNet50,ResNet152。</p>
<h2 id="4-2-ResNet调整"><a href="#4-2-ResNet调整" class="headerlink" title="4.2. ResNet调整"></a>4.2. ResNet调整</h2><p>ResNet-B，ResNet-C是已经提出的调整。论文提出的调整方案是ResNet-D</p>
<h3 id="ResNet-B"><a href="#ResNet-B" class="headerlink" title="ResNet-B"></a>ResNet-B</h3><p><img src="/assets/tricks/figure_2.png" srcset="/img/loading.gif" alt="图2. 3种ResNet调整。Resnet - B修改了ResNet的下采样块。ResNet-C进一步修改输入主干。在此之上，ResNet-D再次修改向下采样块。"></p>
<p>原因：它改变了ResNe的下采样块。实验观察到，路径A中的卷积忽略了输入特征图的四分之三，因为它使用的卷积核大小为1×1，步长为2。</p>
<p>改进：如图2a所示，ResNet-B改变路径A中前两个卷积的步长大小，所以没有信息被忽略。因为第二层卷积的卷积核大小为3×3，因此路径A的输出形状保持不变。</p>
<h3 id="ResNet-C"><a href="#ResNet-C" class="headerlink" title="ResNet-C"></a>ResNet-C</h3><p>出处：此调整最初是在Inception-v2中提出的，可以在其他模型的实现中找到，例如SENet [12]，PSPNet [31]，DeepLabV3 [1]和ShuffleNetV2 [21]。</p>
<p>原因：观察发现，卷积的计算成本是核宽度或高度的平方。一个7×7卷积比3×3卷积贵5.4倍。</p>
<p>改进：图2b所示。此调整将输入主干的7×7卷积替换为三个保守的3×3卷积，其中第一个和第二个卷积的输出通道为32，步长为2，而最后一个卷积使用64输出通道。</p>
<h3 id="ResNet-D"><a href="#ResNet-D" class="headerlink" title="ResNet-D"></a>ResNet-D</h3><p>原因（创新点）：受ResNet-B的启发，我们注意到下采样块路径B中的1×1卷积也忽略了3/4个输入特征图，我们想对其进行修改，因此不会忽略任何信息。</p>
<p>改进：根据经验，我们发现在卷积之前添加一个步长为2的2×2平均池化层（卷积层的步长更改为1）在实践中效果很好，并且对计算成本的影响很小。</p>
<h2 id="4-3-实验结果"><a href="#4-3-实验结果" class="headerlink" title="4.3. 实验结果"></a>4.3. 实验结果</h2><p><img src="/assets/tricks/table_5.png" srcset="/img/loading.gif" alt="表5. 将ResNet-50与模型大小，FLOP和ImageNet验证准确性的三个模型调整进行比较。"><br>实验方案：使用第3节中描述的三种调整和设置来评估ResNet-50，即批量大小为1024，精度为FP16。结果如表5所示。</p>
<p>实验结果：<br>（1）与ResNet-50对比，ResNet-B在下采样块的路径A中可以接收到更多信息，其验证准确性提高了约0.5％。<br>（2）将7×7卷积替换为三个3×3卷积可进一步提高0.2％。在下采样块的路径B中可获的更多信息，可将验证准确度再提高0.3％。</p>
<p>结论：ResNet-50-D将ResNet-50提升了1％。</p>
<p>计算成本对比：四个模型具有相同的模型大小。ResNet-D具有最大的计算成本，但就浮点运算而言，它与ResNet-50的差异在15%以内。实际上，我们观察到，与ResNet-50相比，ResNet-50-D在训练吞吐量方面仅慢3%。</p>
<h1 id="5-训练改进"><a href="#5-训练改进" class="headerlink" title="5 训练改进"></a>5 训练改进</h1><p>在本节中，我们将描述四个训练改进，来进一步提高模型的准确性。</p>
<h2 id="5-1-余弦学习率衰减（Cosine-learning-rate-decay）"><a href="#5-1-余弦学习率衰减（Cosine-learning-rate-decay）" class="headerlink" title="5.1. 余弦学习率衰减（Cosine learning rate decay）"></a>5.1. 余弦学习率衰减（Cosine learning rate decay）</h2><p>来源： Loshchilov（论文：SGDR: stochastic gradient de-scent with restarts）提出一个余弦退火策略。</p>
<p>cosine decay：一个简化的版本是根据余弦函数将学习率从初始值降低到0。假设批次总数为T（忽略预热阶段），则在批次t处，学习率\(\eta_t\)计算为：\({\eta_t = \frac{1}{2} (1 + cos(\frac{t\pi}{T}))\eta }\)。其中\(\eta \)是初始学习率。</p>
<p>cosine decay 和 step decay的对比（图3a）：</p>
<ul>
<li>cosine decay：余弦衰减在开始时缓慢降低学习速度，然后在中间时几乎呈线性下降，在结束时再次减慢。</li>
<li>与step decay相比：余弦衰减从一开始就对学习进行衰减，但在step decay使学习速率降低10倍之前，余弦衰减仍然很大，这可能会提高训练的进度。 </li>
</ul>
<h2 id="5-2-标签平滑（Label-Smoothing）"><a href="#5-2-标签平滑（Label-Smoothing）" class="headerlink" title="5.2. 标签平滑（Label Smoothing）"></a>5.2. 标签平滑（Label Smoothing）</h2><h3 id="标签的常用使用过程"><a href="#标签的常用使用过程" class="headerlink" title="标签的常用使用过程"></a>标签的常用使用过程</h3><ul>
<li><p>标签预测置信度分数-&gt;softmax预测概率：图像分类网络的最后一层通常是一个全连通层，隐藏的大小等于标签的数量，用K表示，用来输出预测的置信度分数。给定一张图像，用\(z_i\)表示第\(i\)类的预测分数。这些分数可以通过softmax函数进行归一化得到预测概率。用q表示softmax运算符q = softmax(z)的输出，i类的概率qi可以通过下式计算：<br>$$<br>q_i = \frac{exp(z_i)}{\sum_{j=1}^{K} exp(z_j)}<br>$$<br>这是很容易看出\({q_i &gt; 0}\)，并且\({\sum_{j=1}^{K} q_i = 1}\)，所以q是一个合理的概率分布。</p>
</li>
<li><p>对标签设置成one-hot向量形式：假设图像的真实标签为y，则如果i = y，则将真实概率分布构造为pi = 1，否则将其构造为0。在训练期间，通过最小化负交叉熵损失来更新模型参数，以使这两个概率分布彼此相似。特别地，通过p的构造方式，我们知道\(l(p,q) = -logp_y = -z_y + log(\sum_{i=1}^{K} exp(z_i)) \),最佳解决方案是\(z_y^* = \) inf，同时保持其他大小足够小。换句话说，它鼓励显著不同的输出得分，这可能导致过度拟合。</p>
</li>
</ul>
<h3 id="标签平滑"><a href="#标签平滑" class="headerlink" title="标签平滑"></a>标签平滑</h3><ul>
<li>起源：标签平滑的思想首先被提出用于训练Inceptionv2。它改变了真实概率的构造为<br>$$<br>q_i=\begin{cases}<br>1-\epsilon,\quad if \quad i=y \\<br>\epsilon / (K-1),\quad otherwise,<br>\end{cases}<br>$$<br>其中\(\epsilon\)是一个小常数。</li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/论文翻译/">论文翻译</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2019/12/01/ration/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文翻译-在神经编码中的理性想法</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2019/09/25/refining_dan/">
                        <span class="hidden-mobile">深度炼丹之路--one day</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "论文翻译-使用卷积神经网络图像分类的技巧包&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>


















</body>
</html>
