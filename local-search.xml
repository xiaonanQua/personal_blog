<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2020/01/31/guide/"/>
    <url>/2020/01/31/guide/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本篇团队服务器使用指南，主要解决用户远程使用服务器计算资源，多版本python管理等问题。</p></blockquote><blockquote><p>@Author：小南</p></blockquote><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><!-- TOC --><ul><li><a href="#目录">目录</a></li><li><a href="#一食用方法">一、食用方法</a><ul><li><a href="#11必备技巧">1.1、必备技巧</a></li><li><a href="#12用户类">1.2、用户类</a><ul><li><a href="#121linux用户ubuntu系列">1.2.1、Linux用户（Ubuntu系列）</a></li><li><a href="#122windows用户">1.2.2、Windows用户</a></li></ul></li><li><a href="#13管理员类">1.3、管理员类</a></li></ul></li><li><a href="#二配置本地和远程机器的ssh">二、配置本地和远程机器的SSH</a><ul><li><a href="#21-linux系统ubuntu系列">2.1、 Linux系统（Ubuntu系列）</a><ul><li><a href="#211安装openssh-client">2.1.1、安装openssh-client</a></li><li><a href="#212安装openssh-server">2.1.2、安装openssh-server</a></li><li><a href="#213ssh常见服务命令">2.1.3、ssh常见服务命令</a></li><li><a href="#214ssh连接操作">2.1.4、ssh连接操作</a></li></ul></li><li><a href="#22windows系统">2.2、windows系统</a></li><li><a href="#23-参考文献">2.3、 参考文献</a></li></ul></li><li><a href="#三使用pyenv对多版本的python进行管理">三、使用pyenv对多版本的python进行管理</a><ul><li><a href="#31安装pyenv">3.1、安装pyenv</a><ul><li><a href="#311预先准备满足后续安装python包的要求直接复制到终端即可">3.1.1、预先准备（满足后续安装python包的要求，直接复制到终端即可）</a></li><li><a href="#312安装两者各选其一推荐第一种">3.1.2、安装（两者各选其一，推荐第一种）</a></li><li><a href="#313配置环境将pyenv加入bashrc中这是当前用户中若是root则修改bash_profile-">3.1.3、配置环境（将pyenv加入.bashrc中，这是当前用户中。若是root，则修改.bash_profile ）</a></li><li><a href="#314更新pyenv">3.1.4、更新pyenv</a></li><li><a href="#315删除pyenv">3.1.5、删除pyenv</a></li></ul></li><li><a href="#32配置及管理多个python版本">3.2、配置及管理多个python版本</a><ul><li><a href="#321安装python版本">3.2.1、安装python版本</a></li><li><a href="#322卸载python版本">3.2.2、卸载python版本</a></li><li><a href="#323pyenv的三个基础命令">3.2.3、pyenv的三个基础命令</a></li><li><a href="#324各个python版本切换操作">3.2.4、各个python版本切换操作</a></li></ul></li><li><a href="#33配置虚拟环境及jupyter使用虚拟环境">3.3、配置虚拟环境及jupyter使用虚拟环境</a><ul><li><a href="#331创建虚拟环境">3.3.1、创建虚拟环境</a></li><li><a href="#332jupyter使用虚拟环境">3.3.2、Jupyter使用虚拟环境</a></li></ul></li><li><a href="#34参考文献">3.4、参考文献</a></li></ul></li><li><a href="#四通过ssh本地调用远程计算资源pycharmjupyterlab配置">四、通过SSH本地调用远程计算资源（Pycharm，JupyterLab配置）</a><ul><li><a href="#41linux系统ubuntu系列">4.1、Linux系统（Ubuntu系列）</a><ul><li><a href="#411pycharm版本20193实现">4.1.1、Pycharm(版本2019.3)实现</a></li><li><a href="#412jupyterlab实现">4.1.2、JupyterLab实现</a></li></ul></li><li><a href="#42windows系统">4.2、Windows系统</a><ul><li><a href="#421pycharm版本20193实现">4.2.1、Pycharm(版本2019.3)实现</a></li><li><a href="#422jupyterlab实现">4.2.2、JupyterLab实现</a></li></ul></li></ul></li><li><a href="#5常见系统问题">5、常见系统问题</a><ul><li><a href="#51防止黑客攻击">5.1、防止黑客攻击</a></li><li><a href="#52参考文献">5.2、参考文献</a></li></ul></li></ul><!-- /TOC --><h1 id="一、食用方法"><a href="#一、食用方法" class="headerlink" title="一、食用方法"></a>一、食用方法</h1><blockquote><p>指南分为两类食用方法，用户类，管理员类。用户只需遵循指南进行配置，完成日常所需。系统管理员类需仔细阅读指南的整体配置流程。</p></blockquote><h2 id="1-1、必备技巧"><a href="#1-1、必备技巧" class="headerlink" title="1.1、必备技巧"></a>1.1、必备技巧</h2><p>在使用系统之前，必须先了解两个linux监督工具：htop和nvidia-smi。</p><p><strong>htop是用来监督系统CPU的使用情况，nvidia-smi是用来监督GPU的使用情况。对于每个用户，需要这两个工具监督机器的内存和显存是否达到极限值，若达到则立即停止程序运行！</strong></p><blockquote><p>为什么要熟练使用这两种工具？主要因为服务器是个公共机器，多人使用的话。如果操作不当，很容易让服务器内存占满，从而导致机器变得非常卡，什么操作都进行不了，最后得重启才能解决。更糟糕的情况是系统坏掉，一切部署的文件将化为乌有。又得从头开始慢慢配置各种环境，不由得会感叹‘实验没做多少，倒忙的很！’</p></blockquote><p>具体操作代码及示例如下所示：</p><ul><li><p>htop  //终端命令，监督CPU情况</p></li><li><p>watch -n 0.5 nvidia-smi  //终端命令，监督GPU情况，每0.5秒刷新</p></li></ul><p>htop示例图，图像中每个参数含义可参照这篇博客。<a href="https://blog.csdn.net/freeking101/article/details/79173903" target="_blank" rel="noopener">htop中参数含义</a></p><p><img src="guide/24.png" srcset="/img/loading.gif" alt></p><p>nvidia-smi示例图，图像中每个参数含义可参照这篇博客。<a href="https://blog.csdn.net/C_chuxin/article/details/82993350" target="_blank" rel="noopener">nvidia-smi的参数含义</a></p><p><img src="guide/25.png" srcset="/img/loading.gif" alt></p><h2 id="1-2、用户类"><a href="#1-2、用户类" class="headerlink" title="1.2、用户类"></a>1.2、用户类</h2><blockquote><p>用户分为Linux和windows两用户，这里只说明各个用户如何阅读下文的标题号来配置环境。</p></blockquote><h3 id="1-2-1、Linux用户（Ubuntu系列）"><a href="#1-2-1、Linux用户（Ubuntu系列）" class="headerlink" title="1.2.1、Linux用户（Ubuntu系列）"></a>1.2.1、Linux用户（Ubuntu系列）</h3><p><strong>Step1 配置SSH：<a href="#2.1.1、安装openssh-client">2.1.1</a>–&gt;<a href="#2.1.3、ssh常见操作命令">2.1.3</a></strong></p><p><strong>Step2 配置虚拟环境：<a href="#3.3.1、创建虚拟环境">3.3.1</a>–&gt;<a href="#3.3.2、jupyter使用虚拟环境">3.3.2</a>或者<a href="#3.3.1、创建虚拟环境">3.3.1</a></strong></p><p><strong>Step3 配置调用远程计算资源：<a href="#4.1.1、Pycharm(版本2019.3)实现">4.1.1</a>或<a href="#4.1.2、JupyterLab实现">4.1.2</a></strong></p><h3 id="1-2-2、Windows用户"><a href="#1-2-2、Windows用户" class="headerlink" title="1.2.2、Windows用户"></a>1.2.2、Windows用户</h3><p><strong>Step1 配置SSH（安装Xshell）：<a href="#2.2、windows系统">2.2</a></strong></p><p><strong>Step2 配置虚拟环境：<a href="#3.3.1、创建虚拟环境">3.3.1</a>–&gt;<a href="#3.3.2、jupyter使用虚拟环境">3.3.2</a>或者<a href="#3.3.1、创建虚拟环境">3.3.1</a></strong></p><p><strong>Step3 配置调用远程计算资源：<a href="#4.1.1、Pycharm(版本2019.3)实现">4.1.1</a>或<a href="#4.2.2、JupyterLab实现">4.2.2</a></strong></p><h2 id="1-3、管理员类"><a href="#1-3、管理员类" class="headerlink" title="1.3、管理员类"></a>1.3、管理员类</h2><p><strong>管理员类需熟悉文档的所有配置流程，掌控系统的功能要点，并及时更新文档说明，达到维护系统的管理员职责!</strong></p><h1 id="二、配置本地和远程机器的SSH"><a href="#二、配置本地和远程机器的SSH" class="headerlink" title="二、配置本地和远程机器的SSH"></a>二、配置本地和远程机器的SSH</h1><blockquote><p>ssh的含义、作用，就不赘述了，可参考这个博客。<a href="https://blog.csdn.net/netwalk/article/details/12951031" target="_blank" rel="noopener">博客链接</a>。这里解决本地机器和远程机器之间进行远程连接问题，包括linux和windows两系统解决方案。ssh含义</p></blockquote><blockquote><p>在阐述之前，先定义（虚构）本地机器（用户名：local）的ip地址为：192.168.112.1，远程机器（用户名：remote）的ip地址：192.168.112.2。本地机器的操作系统是Linux或者windows，远程机器的操作系统是Ubuntu16.04。</p></blockquote><blockquote><p>废话说明：你可以发现这两个机器是在局域网里，两者之间是肯定能互通。如果两个机器之间无法连通起来，这有可能一个是内网，一个是外网，两者之间是不能互通，通常需要对内网进行端口映射，一般是买个云服务器做个端口转发。本文假设两者之间是能互通，若不通的话请自行百度解决。</p></blockquote><h2 id="2-1、-Linux系统（Ubuntu系列）"><a href="#2-1、-Linux系统（Ubuntu系列）" class="headerlink" title="2.1、 Linux系统（Ubuntu系列）"></a>2.1、 Linux系统（Ubuntu系列）</h2><h3 id="2-1-1、安装openssh-client"><a href="#2-1-1、安装openssh-client" class="headerlink" title="2.1.1、安装openssh-client"></a>2.1.1、安装openssh-client</h3><p>openssh-client是客户端，它的作用是只想登录别的机器的ssh，也就是本地机器用来登录远程机器。安装在local机器中，安装代码如下（打开终端）：</p><ul><li>sudo apt-get install openssh-client  //安装客户端到local机器中</li><li>ssh-keygen  //生成私钥和公钥，一直按回车默认即可</li></ul><h3 id="2-1-2、安装openssh-server"><a href="#2-1-2、安装openssh-server" class="headerlink" title="2.1.2、安装openssh-server"></a>2.1.2、安装openssh-server</h3><p>openssh-server是服务端，用来开放ssh服务，也就是以本机作为远程（remote）服务器，让其他机器访问自己。安装在remote机器中，安装代码如下（打开终端）：</p><ul><li>sudo apt-get install openssh-server   //安装服务端到remote机器中。</li><li>sudo ps -e |grep ssh  //查看ssh有没有打开</li><li>sudo /etc/init.d/ssh start //（可选）打开ssh</li></ul><h3 id="2-1-3、ssh常见服务命令"><a href="#2-1-3、ssh常见服务命令" class="headerlink" title="2.1.3、ssh常见服务命令"></a>2.1.3、ssh常见服务命令</h3><ul><li><p>sudo service ssh [stop, start, restart] // 快捷[停止、开启、重启]服务命令或者选择下面的命令</p></li><li><p>sudo /etc/init.d/ssh stop  //停止服务</p></li><li><p>sudo /etc/init.d/ssh start  //启动服务</p></li><li><p>sudo /etx/init.d/ssh restart //重启服务</p></li><li><p>exit  //断开连接</p></li></ul><h3 id="2-1-4、ssh连接操作"><a href="#2-1-4、ssh连接操作" class="headerlink" title="2.1.4、ssh连接操作"></a>2.1.4、ssh连接操作</h3><blockquote><p>实现自动登录，将本地机器的ssh公钥拷贝到远程机器的ssh中，下次连接只需添加按照下面的连接就可以，不需要添加密码。当然第一次添加是需要输入密码的，还需要管理员将修改远程机器ssh的配置文件，开放密码登录的权限。<strong>具体修改配置可参考<a href="https://www.linuxidc.com/Linux/2015-07/119608.htm" target="_blank" rel="noopener">博客</a>[管理员负责]</strong>。</p></blockquote><ul><li><p>ssh-copy-id -i /home/xiaonan/.ssh/id_rsa.pub <a href="mailto:remote@192.168.112.2" target="_blank" rel="noopener">remote@192.168.112.2</a> -p 22  //（配置）将本地ssh公钥复制到远程机器的ssh中</p></li><li><p>ssh <a href="mailto:remote@192.168.112.2" target="_blank" rel="noopener">remote@192.168.112.2</a> -p 22 -o ServerAliveInterval=60  //(日常连接)连接远程机器，’-p’是设置端口，‘-o’操作是设置防止无操作而断开连接。</p></li></ul><h2 id="2-2、windows系统"><a href="#2-2、windows系统" class="headerlink" title="2.2、windows系统"></a>2.2、windows系统</h2><blockquote><p>在windows里使用Xshell来连接远程Linux，<a href="http://wm.makeding.com/iclk/?zoneid=18724" target="_blank" rel="noopener">Xshell下载地址</a>。</p></blockquote><p>打开Xshell，新建服务器的连接客户端，配置远程主机的ip地址，然后点击用户身份验证，输入远程机器的用户名和密码。</p><p><img src="guide/19.png" srcset="/img/loading.gif" alt></p><h2 id="2-3、-参考文献"><a href="#2-3、-参考文献" class="headerlink" title="2.3、 参考文献"></a>2.3、 参考文献</h2><ul><li><a href="https://blog.csdn.net/netwalk/article/details/12952051" target="_blank" rel="noopener">Ubuntu环境下SSH的安装及使用</a></li></ul><h1 id="三、使用pyenv对多版本的python进行管理"><a href="#三、使用pyenv对多版本的python进行管理" class="headerlink" title="三、使用pyenv对多版本的python进行管理"></a>三、使用pyenv对多版本的python进行管理</h1><h2 id="3-1、安装pyenv"><a href="#3-1、安装pyenv" class="headerlink" title="3.1、安装pyenv"></a>3.1、安装pyenv</h2><blockquote><p>安装pyenv参照官方文档安装（当前写的文档有可能会跟官方有出入，请查阅之后再安装！）<a href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener">官方地址链接</a>。<br>本人服务器系统是ubuntu系列系统，官方也给出了其他系统的安装方法，这里不在赘述。安装我选择了自动安装器（automatic instller）<a href="https://github.com/pyenv/pyenv-installer" target="_blank" rel="noopener">安装地址链接</a></p></blockquote><h3 id="3-1-1、预先准备（满足后续安装python包的要求，直接复制到终端即可）"><a href="#3-1-1、预先准备（满足后续安装python包的要求，直接复制到终端即可）" class="headerlink" title="3.1.1、预先准备（满足后续安装python包的要求，直接复制到终端即可）"></a>3.1.1、预先准备（满足后续安装python包的要求，直接复制到终端即可）</h3><ul><li><p>sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python-openssl git</p></li><li><p>sudo apt install libedit-dev</p></li></ul><h3 id="3-1-2、安装（两者各选其一，推荐第一种）"><a href="#3-1-2、安装（两者各选其一，推荐第一种）" class="headerlink" title="3.1.2、安装（两者各选其一，推荐第一种）"></a>3.1.2、安装（两者各选其一，推荐第一种）</h3><ul><li>curl <a href="https://pyenv.run" target="_blank" rel="noopener">https://pyenv.run</a> | bash</li><li>curl -L <a href="https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer" target="_blank" rel="noopener">https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer</a> | bash</li></ul><h3 id="3-1-3、配置环境（将pyenv加入-bashrc中，这是当前用户中。若是root，则修改-bash-profile-）"><a href="#3-1-3、配置环境（将pyenv加入-bashrc中，这是当前用户中。若是root，则修改-bash-profile-）" class="headerlink" title="3.1.3、配置环境（将pyenv加入.bashrc中，这是当前用户中。若是root，则修改.bash_profile ）"></a>3.1.3、配置环境（将pyenv加入.bashrc中，这是当前用户中。若是root，则修改.bash_profile ）</h3><ul><li><p>sudo gedit .bashrc</p></li><li><p>在.bashrc文件的底部空白处，添加三行命令(第一条的用户路径根据实际情况进行修改)：</p><pre><code class="hljs undefined">export PATH=&quot;/home/xiaonan/.pyenv/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot; eval &quot;$(pyenv virtualenv-init -)&quot;</code></pre></li><li><p>重启终端（SHELL）输入：pyenv –version，打印版本信息，则说明安装成功</p></li></ul><h3 id="3-1-4、更新pyenv"><a href="#3-1-4、更新pyenv" class="headerlink" title="3.1.4、更新pyenv"></a>3.1.4、更新pyenv</h3><ul><li>pyenv update</li></ul><h3 id="3-1-5、删除pyenv"><a href="#3-1-5、删除pyenv" class="headerlink" title="3.1.5、删除pyenv"></a>3.1.5、删除pyenv</h3><ul><li><p>rm -fr .pyenv</p></li><li><p>删除.bashrc文件中（在配置环境过程中）添加的三个命令</p></li><li><p>重启终端</p></li></ul><h2 id="3-2、配置及管理多个python版本"><a href="#3-2、配置及管理多个python版本" class="headerlink" title="3.2、配置及管理多个python版本"></a>3.2、配置及管理多个python版本</h2><h3 id="3-2-1、安装python版本"><a href="#3-2-1、安装python版本" class="headerlink" title="3.2.1、安装python版本"></a>3.2.1、安装python版本</h3><blockquote><p>通过实践发现，按照官方的安装方法，在下载对应版本的python下载速度很慢。所以，本人不采用官方的方法，具体流程如下！</p></blockquote><ul><li><p>mkdir /home/xiaonan/.pyenv/cache  （若没有cache文件夹则新建，若已有则跳过此步。这里文件路径根据自己的情况进行修改，即/××/××/.pyenv/cache）</p></li><li><p>前往python官网下载自己想要的python版本（稳定版，即stable），文件格式是***.tar.xz，即是xz压缩的文件。<a href="https://www.python.org/downloads/source/" target="_blank" rel="noopener">下载链接</a></p></li><li><p>cp Python-3.8.1.tar.xz /home/xiaonan/.pyenv/cache   （将下载后的文件移动到cache文件中，这里文件路径根据自己情况进行修改。）</p></li><li><p>pyenv install 3.8.1    （安装例如上述python3.8的版本）</p></li><li><p>pyenv versions             （查看系统安装的python ）</p></li></ul><h3 id="3-2-2、卸载python版本"><a href="#3-2-2、卸载python版本" class="headerlink" title="3.2.2、卸载python版本"></a>3.2.2、卸载python版本</h3><ul><li>pyenv uninstall 3.7.1</li></ul><h3 id="3-2-3、pyenv的三个基础命令"><a href="#3-2-3、pyenv的三个基础命令" class="headerlink" title="3.2.3、pyenv的三个基础命令"></a>3.2.3、pyenv的三个基础命令</h3><ul><li><p>pyenv global <python version>   //配置当前用户系统使用的python版本</python></p></li><li><p>pyenv shell <python version>  //配置当前shell（终端）的python版本，退出shell则失效！</python></p></li><li><p>pyenv local <python version> //配置所在目录（项目）的python版本</python></p></li><li><p>pyenv local system  //切换成系统自带的python的版本</p></li></ul><h3 id="3-2-4、各个python版本切换操作"><a href="#3-2-4、各个python版本切换操作" class="headerlink" title="3.2.4、各个python版本切换操作"></a>3.2.4、各个python版本切换操作</h3><blockquote><p>本人系统自带的是python3.6，后来又通过上述安装操作，安装了python3.7和3.8，现在演示各个情况下的切换。</p></blockquote><ul><li><p>pyenv versions  //查看拥有的python版本</p></li><li><p>使用pyenv global <version>配置当前用户的系统使用的python版本</version></p>  <pre><code class="hljs undefined">pyenv global  3.7.6pyenv rehash  //对数据库进行更新，才算对当前用户切换完成！若出现无法切换版本的问题，一般是因为用pyenv指定了local版本。执行&quot;pyenv local --unset&quot;，取消设置local版本。</code></pre></li></ul><ul><li><p>使用pyenv shelll <version>配置当前shell的python版本，退出shell则失效</version></p><pre><code class="hljs undefined">pyenv shell 3.7.6      //只在当前shell(终端)窗口有效, 退出重新登录 或 再打开另外一个窗口不生效pyenv shell --unset   //取消当前shell的设置</code></pre></li><li><p>使用pyenv local <version>配置所在项目（目录）的python版本</version></p><pre><code>mkdir test   //实验新建新的文件夹，可以跳过此步，直接想要指定的目录cd testpyenv local 3.7.6pyenv versions  //查看当前文件夹的版本</code></pre></li></ul><h2 id="3-3、配置虚拟环境及jupyter使用虚拟环境"><a href="#3-3、配置虚拟环境及jupyter使用虚拟环境" class="headerlink" title="3.3、配置虚拟环境及jupyter使用虚拟环境"></a>3.3、配置虚拟环境及jupyter使用虚拟环境</h2><blockquote><p>通过以上操作，已经在服务器中部署了五个python版本（系统自带：python3.5、python2.7，新部署(pyenv管理)：python3.6&lt;3.6.8&gt;、python3.7&lt;3.7.6&gt;、python3.8&lt;3.8.1&gt;）。</p></blockquote><blockquote><p>为了防止多用户使用时扰乱系统环境，所以这里设置了使用指南，规范大家的使用。只需修改部分名称，其他的指令可直接粘贴。</p></blockquote><blockquote><p>另外说明：没有考虑将Anaconda虚拟环境纳入管理，<strong>通过Anaconda创建虚拟环境的用户可跳过此步。</strong> 这里创建虚拟环境的工具是venv，其他工具未补充。</p></blockquote><h3 id="3-3-1、创建虚拟环境"><a href="#3-3-1、创建虚拟环境" class="headerlink" title="3.3.1、创建虚拟环境"></a>3.3.1、创建虚拟环境</h3><p><strong>下面在终端的操作指令：</strong></p><ul><li><p>pyenv versions        //查看pyenv管理下的python版本</p></li><li><p>pyenv shell 3.6.8    //设置当前终端（shell）的python环境是3.6.8。（当终端关闭时，设置会自动消失，不会对原有系统环境造成影响。若使用系统原有的python3.5，python2.7，则跳过此步！）</p></li><li><p>python -V    //查看当前的系统python版本</p></li><li><p>python -m venv test //（pyenv管理的环境）创建虚拟环境，用户只需把“test”换成自己的虚拟环境的名称。</p></li><li><p>python\python3 -m venv test //（使用python3.5、2.7的环境）创建虚拟环境，用户只需把‘test’换成自己的虚拟环境名称</p></li><li><p>source test/bin/activate  //激活虚拟环境，会发现终端出现虚拟环境的名字。当然，这里也可以重进终端进行激活。</p></li><li><p>python -V  //查看虚拟环境的python版本</p></li><li><p>deactivate  //退出虚拟环境</p></li></ul><p><img src="guide/1.png" srcset="/img/loading.gif" alt></p><p><strong>额外补充:打包依赖库和安装依赖库</strong></p><ul><li><p>pip freeze  &gt; deployment.txt  //将系统python库或者虚拟环境python（需激活）写入文本</p></li><li><p>pip install -r deployment.txt  //安装依赖文件中的python库</p></li><li><p>cat deployment.txt | xargs -n 1 pip install //（推荐）安装依赖文件中的python库，并可跳过缺少的库</p></li></ul><p><strong>关于venv创建虚拟环境其他的功能，可参考官方Python文档。<a href="https://docs.python.org/zh-cn/3/tutorial/venv.html" target="_blank" rel="noopener">Python文档</a></strong></p><h3 id="3-3-2、Jupyter使用虚拟环境"><a href="#3-3-2、Jupyter使用虚拟环境" class="headerlink" title="3.3.2、Jupyter使用虚拟环境"></a>3.3.2、Jupyter使用虚拟环境</h3><p><strong>在上述创建虚拟环境操作之后，重启一个终端，并输入如下命令：</strong></p><ul><li><p>source test/bin/activate  //激活虚拟环境，这里的虚拟环境只是用来说明，用户可以换成自己的虚拟环境。</p></li><li><p>pip install jupyter   //（可选操作，不推荐）在激活的虚拟环境下安装jupyter notebook</p></li><li><p>pip install jupyterlab  //(可选操作， 推荐)，在激活的虚拟环境下安装jupyter lab</p></li><li><p>ipython kernel install –name ‘test’ –user  //将虚拟环境安装到jupyter内核中（给用户权限），这里的’test’就是前面新建的虚拟环境的名称，换用自己对应的虚拟环境即可。</p></li><li><p>cd /home/team/.local/share/jupyter/kernels/  &amp;&amp; ls  //查看jupyter内核中是否存在刚刚创建的虚拟环境</p></li><li><p>rm -r test  //(可选操作，删除操作)进入上面jupyter内核中删除指定的虚拟环境文件夹即可。</p></li></ul><p><strong>关于JupyterLab的使用技巧，可以参考这篇文章。<a href="https://zhuanlan.zhihu.com/p/67959768" target="_blank" rel="noopener">JupyterLab使用技巧</a></strong></p><p><img src="guide/2.png" srcset="/img/loading.gif" alt><br><img src="guide/3.png" srcset="/img/loading.gif" alt><br><img src="guide/4.png" srcset="/img/loading.gif" alt><br><img src="guide/5.png" srcset="/img/loading.gif" alt></p><h2 id="3-4、参考文献"><a href="#3-4、参考文献" class="headerlink" title="3.4、参考文献"></a>3.4、参考文献</h2><ul><li><p><a href="https://www.cnblogs.com/kevingrace/p/10130801.html" target="_blank" rel="noopener">Python多版本管理器-pyenv 介绍及部署记录</a></p></li><li><p><a href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener">pyenv官方地址链接</a>。</p></li><li><p><a href="https://github.com/pyenv/pyenv-installer" target="_blank" rel="noopener">pyenv安装地址链接</a></p></li><li><p><a href="https://docs.python.org/zh-cn/3/tutorial/venv.html" target="_blank" rel="noopener">Python文档</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/67959768" target="_blank" rel="noopener">JupyterLab使用技巧</a></p></li></ul><h1 id="四、通过SSH本地调用远程计算资源（Pycharm，JupyterLab配置）"><a href="#四、通过SSH本地调用远程计算资源（Pycharm，JupyterLab配置）" class="headerlink" title="四、通过SSH本地调用远程计算资源（Pycharm，JupyterLab配置）"></a>四、通过SSH本地调用远程计算资源（Pycharm，JupyterLab配置）</h1><h2 id="4-1、Linux系统（Ubuntu系列）"><a href="#4-1、Linux系统（Ubuntu系列）" class="headerlink" title="4.1、Linux系统（Ubuntu系列）"></a>4.1、Linux系统（Ubuntu系列）</h2><h3 id="4-1-1、Pycharm-版本2019-3-实现"><a href="#4-1-1、Pycharm-版本2019-3-实现" class="headerlink" title="4.1.1、Pycharm(版本2019.3)实现"></a>4.1.1、Pycharm(版本2019.3)实现</h3><p><strong>Step1 将本地项目同步到远程服务中：</strong></p><p>1、打开Pycharm，选择导航栏，依次选择：Tools–&gt;Deployment–&gt;Configuration</p><p><img src="guide/6.png" srcset="/img/loading.gif" alt></p><p>2、选择最上的+，再选择SFTP协议，输入名称，填写相关信息（如下图所示）</p><p><img src="guide/7.png" srcset="/img/loading.gif" alt></p><p>3、修改Mappings中的Deployment path：/</p><p><img src="guide/8.png" srcset="/img/loading.gif" alt></p><p>4、修改Excluded Paths中的Deployment path，将远程服务器中的部分文件排除在同步的文件中。点击OK完成</p><p><img src="guide/9.png" srcset="/img/loading.gif" alt></p><p><strong>Step2 配置远程服务器的Python解释器:</strong></p><p>1、打开导航栏：Files–&gt;Settings–&gt;Project Interpreter</p><p><img src="guide/10.png" srcset="/img/loading.gif" alt></p><p>2、点击齿轮来添加解释器，选择SSH Interpreter，选择存在的server configuration，也就是刚刚配置的项目，点击Move进行下一步的配置。</p><p><img src="guide/11.png" srcset="/img/loading.gif" alt></p><p>3、修改默认的python解释器为上面设置的虚拟环境解释器。修改同步目录，将默认的远程值改成自己项目的根（/）下，最后点击Finish。</p><p><img src="guide/13.png" srcset="/img/loading.gif" alt><br><img src="guide/12.png" srcset="/img/loading.gif" alt></p><p>4、测试结果，在本地新建test.py，并输出‘Hello World’，按Ctrl+S会保存本地文件并同步到远程服务器的项目中。运行文件，会发现计算是在远程服务器完成的，没有占用本机的计算资源。</p><p><img src="guide/14.png" srcset="/img/loading.gif" alt></p><h3 id="4-1-2、JupyterLab实现"><a href="#4-1-2、JupyterLab实现" class="headerlink" title="4.1.2、JupyterLab实现"></a>4.1.2、JupyterLab实现</h3><blockquote><p>JupyterLab使用远程计算资源，主要是通过ssh建立本地（local）机器和远程（remote）机器端口转发隧道，即两个机器之间建立端口对接，保持远程机器中的JupyterLab端口映射到本地机器，本地机器可以类似于在本地安装了JupyterLab并使用它。</p></blockquote><blockquote><p><strong>使用说明</strong>：通过实验发现，在远程机器后台打开了JupyterLab，用户在本地机器使用它，当用户运行一些程序并且占用计算资源（内存）。若远程机器没有关闭JupyterLab，则程序会一直占用计算资源（内存）得不到释放。所以，这里设置了一些使用规范，虽然会稍有点麻烦，但能更充分的使用计算资源（内存）。</p></blockquote><p>1、本地机器打开终端，并通过ssh连接上远程机器。这里假定远程机器（用户名：remote）的ip地址，具体ip视自己机器而定，ip地址：192.168.111.2</p><ul><li><p>ssh <a href="mailto:remote@192.168.111.2" target="_blank" rel="noopener">remote@192.168.111.2</a> -p 22   //连接上远程机器，接下来会让输入用户密码。</p></li><li><p>cd xiaonan/    //进入自己的文件夹中</p></li><li><p>jupyter lab –no-browser  –port=1222  //端口可随意设置，若出现报错，有可能和其他端口冲突，改变可用端口即可。实验室使用规范：研一同学使用1000～1999范围内的端口，研二同学使用2000～2999，研三同学使用3000～3999。</p></li></ul><p><img src="guide/15.png" srcset="/img/loading.gif" alt></p><p>2、再重新打开一个终端，建立本地机器和远程机器的端口隧道。</p><ul><li>ssh <a href="mailto:remote@192.168.111.2" target="_blank" rel="noopener">remote@192.168.111.2</a> -p 22 -NL 1234:localhost:1222  //-p 22:这是ssh的端口，1234:localhost:1222，第一个1234是本地机器端口，可以随意设置。第二个1222即是上述建立的端口。</li></ul><p><img src="guide/16.png" srcset="/img/loading.gif" alt></p><ul><li>打开本地浏览器，输入localhost:1234，输入登录密码（远程用户的密码）。</li></ul><p><img src="guide/17.png" srcset="/img/loading.gif" alt><br><img src="guide/18.png" srcset="/img/loading.gif" alt></p><h2 id="4-2、Windows系统"><a href="#4-2、Windows系统" class="headerlink" title="4.2、Windows系统"></a>4.2、Windows系统</h2><h3 id="4-2-1、Pycharm-版本2019-3-实现"><a href="#4-2-1、Pycharm-版本2019-3-实现" class="headerlink" title="4.2.1、Pycharm(版本2019.3)实现"></a>4.2.1、Pycharm(版本2019.3)实现</h3><blockquote><p>window的配置类似于Linux中的配置，可以查看上述Linux的配置流程。</p></blockquote><h3 id="4-2-2、JupyterLab实现"><a href="#4-2-2、JupyterLab实现" class="headerlink" title="4.2.2、JupyterLab实现"></a>4.2.2、JupyterLab实现</h3><blockquote><p>Jupyter的实现原理在Linux实现中已阐述，可查看上述。下面具体讲述使用Xshell配置流程。</p></blockquote><p>1、打开Xshell，新建Jupyter的连接客户端，配置远程主机的ip地址，然后点击用户身份验证，输入远程机器的用户名和密码。</p><p><img src="guide/20.png" srcset="/img/loading.gif" alt><br><img src="guide/21.png" srcset="/img/loading.gif" alt></p><p>2、为了能方便登录进远程机器之后直接打开Jupyter Lab，这里设置了登录脚本，点击登录脚本。添加两个命令：</p><ul><li><p>cd  xiaonan/  //进入自己的文件目录</p></li><li><p>jupyter lab –no-browser –port=2212 //端口号随意设置，但要记住后续需要用到，并不和系统中存在的端口号冲突</p></li></ul><p>具体操作如图所示：</p><p><img src="guide/22.png" srcset="/img/loading.gif" alt></p><p>3、在远程机器打开了后台JupyterLab，我们需要在本地机器上建立和远程机器JupyterLab的端口隧道，来实现本地机器使用JupyterLab。具体操作：点击隧道，点击添加按钮，添加如图所示的信息。本地端口可以随意设置，只要不和本地机器的端口冲突即可，远程端口就是步骤2设置的JupyterLab端口，这里需要一致，否则不起作用。最后点击确定，然后连接，在浏览器输入localhost:1234。</p><p><img src="guide/23.png" srcset="/img/loading.gif" alt></p><h1 id="5、常见系统问题"><a href="#5、常见系统问题" class="headerlink" title="5、常见系统问题"></a>5、常见系统问题</h1><h2 id="5-1、防止黑客攻击"><a href="#5-1、防止黑客攻击" class="headerlink" title="5.1、防止黑客攻击"></a>5.1、防止黑客攻击</h2><blockquote><p>没想到第一次系统问题竟然是这种硬核的问题，服务器确实遭到了黑客的攻击。根据黑客留下来的文件推测，大概是使用我们服务器进行挖矿（比特币）。2020年2月6号凌晨5点服务器遭到入侵，这也是个苦难的一年（武汉肺炎肆虐），当时我的心真是很难受！我在艰难的防病毒，还得抽出时间来防服务器中毒！当时服务器内存倒是没有占满，而是把六块CPU拉满（总共12块），由于当时过于心急把病毒程序杀掉，没有想起来查看显存如何，大概两块基本都满了！起初用户密码是被修改的，我根本没有没办法通过ssh远程进来。不过，我还是留了一手，也不知道这位黑客是真不知道还是给我留情！我们服务器不是真正的服务器，我们习惯使用Ubuntu这种桌面化的linux系统。我在放假之前在服务器中预留TeamViewer（远程工具），这个工具使得我很快把机器夺回来，要是让他使劲的挖，非把我们的服务器挖坏不可！（而且那个时候因为疫情问题，大家都在家里，根本没有人在学校。）可有个问题，服务器只有一个用户team，现在密码被改了，我该如何进入？有可能你会想到root，可我从游客登录进去从终端没权限登录root，远程也没办法连得上，因为root里我没有安装ssh，我只把ssh安装在了team用户里。后来想起来，我可以通过TeamViewer这个远程界面打开虚拟终端（按Ctrl+F1~6），通过这个终端登录进root！这是个关键，这里也不知道是那个黑客没有考虑修改我的root密码，还是故意给我留一点生机，让我能够摸索到这里！进入root里那不就是拥有最高支配权，通过top找出病毒程序的pid，再通过kill利剑秒杀它，再通过passwd把我的小宝贝team改成我的名下！就这样，折腾到下午的1点半左右，终于把我们的机器夺回来了！我一开始发现是在早上九点多的时候，莫怪我那么晚才起，在家是真的爬不起来。但是，这也只是第一步，我让它的程序不运行了。可它仍躲在系统里，当时通过top是知道执行了什么程序，那是个定时程序，它会在某个时间段重启，所以下面是个漫长的排查之路！首先的思路还是先从那个运行程序入手，通过crontab -l查到小病毒躲在哪里了。当然，在这之前我大量的阅读cron的使用方法，发现也有好多用户类似于这种被攻击。我既然知道了你小东西在哪了，那我的思路就明确了！我把crontab卸载的很彻底，卸载的干干净净，首先不让你在我睡觉的时候重启，其次再把这小东西删的干干津津！这下系统里算干净了！下面考虑的就是防止黑客再次入侵进来，这就需要提升ssh安全级别，这次被攻击也是理所当然的事！像我起了个用户名team，然后密码是team123，然后服务器安然的放到公网里！你说，不攻击你攻击谁！哈哈！通过大量调研，提升安全等级有四个思路：</p><blockquote><p>1、使用SSH秘钥自动登录、服务器禁用SSH口令登录并修改SSH的默认端口！参考<a href="https://blog.csdn.net/yoywow/article/details/52152866" target="_blank" rel="noopener">博客</a></p></blockquote></blockquote><blockquote><blockquote><p>2、把你那傻乎乎的密码改的复杂点，什么叫复杂，就是他们用暴力破解软件破解你的密码需要运行一万亿年！不过，你得吃点苦，每次输入密码时你会很难受！！！<a href="https://suijimimashengcheng.51240.com/" target="_blank" rel="noopener">随机密码</a></p></blockquote></blockquote><blockquote><blockquote><p>3、添加防火墙，组织除了你设置的SSH端口以外的所有连接以及你认为的必要的其他连接。参考<a href="https://www.infvie.com/ops-notes/sshd-violent-cracking.html" target="_blank" rel="noopener">博客</a></p></blockquote></blockquote><blockquote><blockquote><p>4、使用Fail2Ban防御工具，屏蔽黑客多次进行连接失败的ip地址，一般和防火墙一起用！参考<a href="https://www.sundayle.com/fail2ban/" target="_blank" rel="noopener">博客</a></p></blockquote></blockquote><blockquote><p><strong>这家伙(黑客)很阴险！！！</strong> 他恐怕预料到我会抢回机器，把密码改的复杂点，并且也会考虑使用SHH秘钥自动登录，禁用口令提升SHH的安全性，并且会忘记查看服务器用户公钥储存库！因为网上教程都不需要查看，直接从本地添加到服务器里就可以！但我偏不，我通过在服务器里运行命令cat  .ssh/authorized_keys ,发现了蹊跷，有一个神秘用户的公钥在库里待着。我在查看这个库之前，从没有使用过SHH秘钥自动登录！这里说明这个公钥的厉害性，使用这个公钥会使得我上面第一步和第二步的操作都是白费！（端口这里会费点时间，但通过暴力破解都是能进来！）因为远程服务器现在只容许和公钥库中存在的用户公钥匹配才可以进来！你说何其阴险！！后来通过阅读他小病毒的代码，也进一步证实他修改秘钥库的文件，并删除进入系统浏览痕迹！不过，这黑客恐怕像是新手，我还是查出蛛丝马迹！！下面是一些事实的截图！！</p></blockquote><p>1、通过top查看到了cron程序（定时器，运载小病毒）的执行，并拉满了6块cpu！（第一行）</p><p><img src="guide/26.png" srcset="/img/loading.gif" alt></p><p>2、通过cat /var/log/auth.log | grep ‘Accepted’ 命令查看Ubuntu登录者的信息（ip地址），发现一个可疑的ip地址:112.169.152.10，这是韩国首尔地方的ip地址，再结合日期：2月6日5点17，谁那么早就用服务器了！据我所知的人（实验室里的人），应该没有那么早的把！！哈哈！！这黑客删来删去，还是没有删干净！！不行呀！！</p><p><img src="guide/27.png" srcset="/img/loading.gif" alt></p><p>3、通过crontab -l查到了小病毒的藏身之所：/home/team/.bashtemp，从这里又觉得这小哥哥（黑客）挺厉害的，把文件弄成了隐藏文件，而且文件命名很有系统文件的味道！但你的狐狸尾巴还是很好揭示的！进一步查看他的代码，找到了删除系统日志文件和修改秘钥库的代码！！通过查看文件创建时间，是2月6号早上5:46，可以进一步验证这正是小病毒库！</p><p><img src="guide/28.png" srcset="/img/loading.gif" alt></p><p><img src="guide/29.png" srcset="/img/loading.gif" alt></p><p><img src="guide/30.png" srcset="/img/loading.gif" alt></p><p><img src="guide/31.png" srcset="/img/loading.gif" alt></p><p>4、这是当时查看秘钥库时存在的秘钥，秘钥用户名：mdrfckr正是上面图片代码的秘钥！</p><p><img src="guide/32.png" srcset="/img/loading.gif" alt></p><h2 id="5-2、参考文献"><a href="#5-2、参考文献" class="headerlink" title="5.2、参考文献"></a>5.2、参考文献</h2><blockquote><p>本来是一个技术指南，好像写成故事了！不过应该挺不错的把！下面的参考文献可以对于黑客入侵的检测有个认知，可以阅读一下！！</p></blockquote><p><a href="https://cn.bluehost.com/blog/security/8595.html" target="_blank" rel="noopener">黑客有哪些攻击方式攻击网站服务器</a></p><p><a href="https://blog.51cto.com/winhe/2114533" target="_blank" rel="noopener">Linux入*侵分析（二）分析SSH登录日志</a></p><p><a href="http://www.safebase.cn/article-255737-1.html" target="_blank" rel="noopener">SSH入侵事件日志分析和跟踪</a></p><p><a href="https://www.linuxidc.com/Linux/2015-07/119608.htm" target="_blank" rel="noopener">SSH 使用密钥登录并禁止口令登录实践</a></p><p><a href="https://www.jianshu.com/p/cad708536ebb" target="_blank" rel="noopener">Linux服务器被入侵</a></p><p><a href="https://www.infvie.com/ops-notes/sshd-violent-cracking.html" target="_blank" rel="noopener">CentOS7安装Fail2ban+Firewalld防止SSH或vsftpd爆破</a></p><p><a href="https://www.sundayle.com/fail2ban/" target="_blank" rel="noopener">使用 fail2ban 防范暴力破解ssh vsftp 与CC攻击</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>词向量</title>
    <link href="/2019/12/07/nlp/"/>
    <url>/2019/12/07/nlp/</url>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="计算机如何理解单词-一个单词向量入门"><a href="#计算机如何理解单词-一个单词向量入门" class="headerlink" title="计算机如何理解单词:一个单词向量入门"></a>计算机如何理解单词:一个单词向量入门</h1><p>我的计算机到底如何理解单词？ 如果您认为有人藏在您的计算机中，那么我们将为您提供消息!那没有。 但是，有一种非常复杂的算法，非常聪明的数据科学家使用这种东西创建了这种算法 称为词向量。</p><h2 id="什么是词向量引物？"><a href="#什么是词向量引物？" class="headerlink" title="什么是词向量引物？"></a>什么是词向量引物？</h2><p>尽管许多自然语言处理（NLP）算法提供了理解单词和短语的外观，但是这些算法主要用于数字空间中单词的表示。 在NLP中，我们称这些表示为词向量。您可以将向量看作是计算机在特定学习语言的上下文中理解的单词的拼写。 以下博客文章简要介绍了什么是词向量以及如何在NLP研究中使用它们。</p><p><img src="/assets/nlp/1.png" srcset="/img/loading.gif" alt="词向量样例"></p><h2 id="词向量的例子"><a href="#词向量的例子" class="headerlink" title="词向量的例子"></a>词向量的例子</h2><p>单词向量使计算机可以像处理数字值一样处理单词，从而使执行操作和比较它们变得容易。 生成的数字空间特定于所使用的训练数据集。 如果上面显示的向量用在经过不同语料集训练的数字空间中，则数字向量可能指的是完全不同的词。</p><p>与普通话一样，单个单词本身并没有多大意义，但与其他单词组合在一起时具有含义和上下文。 单词向量的工作方式相同。 它们在其他向量的上下文中具有意义。 用于生成数字空间的训练语料库的内容将对单词的联想/含义产生影响。</p><p>这很直观，与我们学习语言的方式相似。 例如，如果允许一个孩子（算法）阅读（处理）的唯一书籍（语料库）是“绿鸡蛋和火腿”，而这个孩子（算法）从未有鸡蛋，则该孩子（算法）可能会认为形容词“ 绿色”通常与名词“鸡蛋”相关联，并且可以假设鸡蛋是绿色的。 这个数字空间内的单词向量的方向包含有关矢量化单词的含义信息。</p><p>非常相似的单词具有指向相似方向的向量。 Kings和Kaisers都是欧洲男性皇室成员； 他们的单词向量将指向相似的方向。 以类似于真实单词的方式，单词矢量可以通过矢量操作串在一起，并且仍然保留含义。 考虑普遍存在的“国王”，“女王”，“男人”和“女人”的例子。 假设您想提到的皇室贵族就像国王，但女人而不是男人。 在经过适当训练的单词向量集中，这些向量操作将使计算机知道您所指的是女王。</p><p><img src="/assets/nlp/2.png" srcset="/img/loading.gif" alt="二维空间中词向量的玩具示例"></p><p>计算机如何学习单词向量集可能会对NLP算法在表示真实语音方面的有效性产生重大影响。 正在迅速进行NLP计算和关联的后台，以查找您键入的单词的数值。 根据这些关联，您的NLP引擎可能会比其他引擎表现更好。 这一切都与数据的上下文和质量有关，这也是一件好事！ 您不希望您的计算机从商店订购绿色鸡蛋……这根本没有意思！</p><h2 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h2><p><strong>语料库：</strong> 大量非结构化文档，可作为自然语言处理算法的训练材料。</p><p><strong>自然语言处理:</strong>能够理解并产生人类语音/语言的应用数学模型。</p><p><strong>词向量：</strong>数字空间中的分布式单词表示形式，用于捕获词汇中的语义关联。</p><h1 id="NLP如何教计算机单词的含义"><a href="#NLP如何教计算机单词的含义" class="headerlink" title="NLP如何教计算机单词的含义"></a>NLP如何教计算机单词的含义</h1><p>人类擅长对话。当某人说某事时，我们能理解他的意思，当银行这样的词在金融机构或河岸的语境中使用时，我们也能理解。我们使用逻辑、语言、情感推理和理解的力量来回应对话。为了让机器像我们一样真正理解自然语言，我们的第一个任务是教它们单词的意义，这是一个说起来容易做起来难的任务。过去几年在这一领域取得了重大进展。我们的第一站比基于神经网络的表现更早。在这个阶段，我们试图教计算机单词或n-gram的存在和不存在。一种简单的方法是使用one-hot编码。</p><h2 id="one-hot-编码向量"><a href="#one-hot-编码向量" class="headerlink" title="one-hot 编码向量"></a>one-hot 编码向量</h2><p>单词在计算机上的表示方式是单词向量的形式。 词向量的最简单形式之一是一热编码向量。 为了理解这个概念，假设我们有一个非常小的词汇表，其中包括：魔术(magic)，龙(dragon)，国王(king)，皇后(queen)。 龙这个词的一个热编码向量看起来像这样：</p><p><img src="/assets/nlp/3.png" srcset="/img/loading.gif" alt></p><p>使用这样的编码，除了在句子中出现和不出现单词外，不会捕捉到任何东西。但是在这篇文章后面所描述的表现是建立在这个想法上的。</p><h2 id="词袋模型-BoW"><a href="#词袋模型-BoW" class="headerlink" title="词袋模型(BoW)"></a>词袋模型(BoW)</h2><p>文档中的每个单词或n-gram都链接到矢量索引。 根据单词的存在或不存在，我们用向量索引在文档中出现的次数来标记向量索引。 该技术广泛用于文档分类。 例如，如果我们将这两个字符串作为文档，“The quick brown fox jumped over the lazy dog.(快速的棕色狐狸跳过了懒惰的狗。)”和“The dog woke up and started chasing the fox.(这只狗醒来并开始追逐狐狸。)”我们可以像下面所示的那样组成一个字典:<br><img src="/assets/nlp/4.png" srcset="/img/loading.gif" alt="统计的词数量"></p><p>然后用每个文档中单词的计数来形成向量。在本例中，我们得到了一个13个元素的向量，每个文档都是这样的。</p><p><img src="/assets/nlp/5.png" srcset="/img/loading.gif" alt></p><p>该方法的局限性在于它会导致极大的特征尺寸和稀疏矢量。 但是，当您只想用几行代码创建基线模型并且数据集较小时，仍可以使用此模型。</p><h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><p>由于BoW只关心单词的出现频率，因此我们在TF – IDF方面迈出了一步。 这是自然语言处理领域中的一种流行算法，并且是术语频率-逆文档频率的缩写。 它衡量单词或n-gram对语料库中文档的重要性。</p><p>文档中的每个单词都有一个分数，该分数随着单词在文档中的出现频率的增加而成比例地增加，但是如果在语料库中太频繁地出现该分数，则会被抵消。TF-IDF值可以用来代替上述向量中的频率计数。由于这是一种统计方法，它仍然不能捕捉单词的含义。</p><p><img src="/assets/nlp/6.png" srcset="/img/loading.gif" alt></p><p>尽管这两种技术有助于解决NLP中的许多问题，但它们仍然没有抓住单词的真实含义。著名的语言学家J·R·弗斯（J.R.Firth）说：``单词的完整含义总是与上下文相关的，除了上下文以外，对任何含义的研究都不能被认真对待。’’ 学习单词嵌入或向量的最简单方法之一是使用神经网络。</p><h2 id="基于神经网络的嵌入"><a href="#基于神经网络的嵌入" class="headerlink" title="基于神经网络的嵌入"></a>基于神经网络的嵌入</h2><p>基于一个词只能在其使用的语境中被完全定义的概念;词嵌入( Word Embeddings)是一种方法来表示一个词的基础上，它的公司保持。在构建单词嵌入时，我们的目标是开发密集的向量表示，以某种方式捕获它们在文档中出现的不同上下文中的含义。在前面的方法中，我们仅使用向量的一个索引来显示单词的存在、不存在或计数。在下面的方法中，我们将转向分布表示。这个表达式使用了整个长度。</p><h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><p>创建分布向量的最流行的方法之一是Word2Vec。它是由Mikolov等人于2013年在谷歌开发的。他们提出了两种不同的方法，连续词包法和连续跳跃图法。为了理解这两个体系结构是如何工作的，让我们来看一下这个示例段落:</p><p>“Harry Potter is by  J. K. Rowling, a  British  author. It is named for its  protagonist  and  hero, the  fictional Harry Potter. The seven books in the series have sold over 500 million copies across the world in over 70 languages and is the best-selling book series of all time. All of them have been made into movies.（《哈利·波特》是英国作家j·k·罗琳的作品。它是以主人公和英雄哈利·波特的名字命名的。该系列的七本书以70多种语言在全球售出了5亿本，是有史以来最畅销的系列书籍。他们都被拍成了电影。）”</p><h3 id="连续词袋-Continuous-Bag-of-Words-CBOW"><a href="#连续词袋-Continuous-Bag-of-Words-CBOW" class="headerlink" title="连续词袋(Continuous Bag of Words ,CBOW)"></a>连续词袋(Continuous Bag of Words ,CBOW)</h3><p>该体系结构旨在根据输入上下文来预测当前单词。 想象一下一个滑动窗口，该窗口在上一段中从一个单词移动到另一个单词。 当窗口位于“幻想”一词上方时，其前面的单词和该单词之后的单词均视为该单词的上下文。</p><p><img src="/assets/nlp/7.png" srcset="/img/loading.gif" alt></p><p>一个one-hot编码的上下文词向量是这个模型的输入。向量的维数为语料库词汇量V。该模型由一个隐层和一个输出层组成。该模型的训练目标是使输出字的条件概率最大。因此，改变W1和W2的权值，直到模型能够实现输出字的高条件概率。</p><p>所以，在我们的例子中，给定前四个单词’a’，’series’，’of’, ‘eight’和后四个单词-‘novel’，’and’，’eight’,’movies’的一个热编码向量，上面所示的CBOW模型是为了最大化在输出层获得’fantasy’的条件概率。应该注意的是，上下文单词输入网络的顺序并不重要。</p><h3 id="连续跳过模型-Continuous-Skip-Grams"><a href="#连续跳过模型-Continuous-Skip-Grams" class="headerlink" title="连续跳过模型(Continuous Skip Grams )"></a>连续跳过模型(Continuous Skip Grams )</h3><p>这个模型与CBOW模型相反。这里，给定一个单词，我们想要预测它通常出现的上下文。以下是该架构的外观:</p><p><img src="/assets/nlp/8.png" srcset="/img/loading.gif" alt></p><p>该模型将输出C个V维向量。C定义为我们希望模型返回的上下文单词的数量，V定义为前一个模型中的总词汇量。对模型进行了训练，使预测误差最小化。因此，当我们对模型的输入是fantasy时，我们期望它返回许多你通常在其中找到fantasy的单词的向量。需要注意的是，当我们增加C时，模型给出了更好的词向量。</p><p>CBOW训练更简单、速度更快，而连续跳跃图模型对不常见单词的训练效果更好。即使我们训练了这两个模型，我们也没有使用它们。我们感兴趣的是模型结束时的权值W。用权矩阵W2表示的权值就变成了我们的字向量。这些词向量然后可以用来初始化神经网络训练执行不同的任务。</p><p>Word2Vec并不是产生连续分布字向量结构的模型，但他们是第一个降低计算复杂度的模型。单词向量的质量取决于用于训练它们的语料库。 Word2Vec最初在Google新闻数据集中接受了16亿个高频单词的训练。 因此，单词向量学习新闻报道领域中使用单词的上下文。</p><h1 id="GloVe和fastText-—-NLP中的两个流行的词向量模型"><a href="#GloVe和fastText-—-NLP中的两个流行的词向量模型" class="headerlink" title="GloVe和fastText — NLP中的两个流行的词向量模型"></a>GloVe和fastText — NLP中的两个流行的词向量模型</h1><p>Miklov等人通过展示两种主要的方法:跳跃图和连续单词包(CBOW)，向世界介绍了单词向量的力量。不久之后，在这些方法的基础上发现了两种更流行的单词嵌入方法。我们将讨论GloVe和fastText，它们是NLP世界中非常流行的单词向量模型。</p><h2 id="全局词向量-Global-Vectors-GloVe"><a href="#全局词向量-Global-Vectors-GloVe" class="headerlink" title="全局词向量(Global Vectors ,GloVe )"></a>全局词向量(Global Vectors ,GloVe )</h2><p>彭宁顿等有人认为word2vec使用的在线扫描方法不是最优的，因为它没有完全利用有关单词共现的全局统计信息。</p><p>在他们称之为全局向量(GloVe)的模型中，他们说:该模型产生了一个具有有意义的子结构的向量空间，其在最近一次单词类比任务中的表现为75%。它在相似度任务和命名实体识别方面也优于相关模型</p><p>为了了解GloVe的工作方式，我们需要了解GloVe建立在两种主要方法上-全局矩阵分解和局部上下文窗口。</p><p>在NLP中，全局矩阵分解是使用线性代数的矩阵分解方法来减少长期频率矩阵的过程。 这些矩阵通常表示文档中单词的出现或不存在。 应用于术语频率矩阵的全局矩阵分解被称为潜在语义分析（LSA）。</p><p>本地上下文窗口方法有CBOW和Skip Gram。跳跃图可以很好地处理少量的训练数据，甚至可以表示被认为是罕见的单词，而CBOW训练速度要快几倍，对于频繁出现的单词的准确性也略好一些。</p><p>这篇论文的作者提到，与其学习原始的共现概率，学习这些共现概率的比率更有用。这有助于更好地区分术语相关性中的细微差别，并提高单词类比任务的性能。</p><p>它是这样工作的：不是从旨在执行不同任务（例如预测相邻词（CBOW）或预测焦点词（Skip-Gram））的神经网络中提取嵌入内容，而是直接优化嵌入内容，以便 两个单词向量的点积等于两个单词彼此靠近出现的次数的对数。</p><p>例如，如果两个单词cat和dog出现在彼此的上下文中，那么在文档语料库中一个10个单词的窗口中出现20次：</p><p><strong>Vector(cat) . Vector(dog) = log(10)</strong></p><p>这就迫使模型对出现在它们附近的单词的频率分布进行编码。</p><h2 id="fasttext"><a href="#fasttext" class="headerlink" title="fasttext"></a>fasttext</h2><p>fastText是word2vec模型的扩展，是另一种单词嵌入方法。fastText并不直接学习单词的向量，而是将每个单词表示为n-gram字符。例如，以n=3的单词artificial为例，这个单词的fastText表示为&lt;ar, art, rti, tif, ifi, fic, ici, ial, al&gt;，其中的尖括号表示单词的开头和结尾。</p><p>这有助于捕获较短单词的含义，并允许嵌入理解后缀和前缀。一旦单词用字符n-gram表示，就会训练一个跳跃图模型来学习嵌入。这个模型被认为是一个单词包模型，在单词上有一个滑动窗口，因为没有考虑单词的内部结构。只要字符在这个窗口内，n-gram的顺序就无关紧要。</p><p>fastText可以很好地处理罕见的单词。所以即使一个单词在训练中没有出现，它也可以被分解成n-gram来得到它的嵌入。</p><p>Word2vec和GloVe都无法为模型字典之外的单词提供任何向量表示。这是这种方法的一个巨大优势。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>我们已经看到了不同的向量方法。GloVe向我们展示了如何利用包含在文档中的全球统计信息。然而，fastText是建立在word2vec模型上的，而不是考虑单词，而是考虑子单词。你可能会问哪种模型是最好的。这取决于你的数据和你要解决的问题</p>]]></content>
    
    
    
    <tags>
      
      <tag>自然语言处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在神经编码中的理性想法</title>
    <link href="/2019/12/01/ration/"/>
    <url>/2019/12/01/ration/</url>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>复杂的行为通常由内部模型驱动，内部模型会随着时间整合感官信息，并促进长期规划以实现主观目标。 我们通过假设代理人行为合理来解释行为数据，也就是说，他们根据对任务及其相关因果的理解，采取可以优化其主观奖励的行动。我们采用了一种新的方法，即反向理性控制（IRC），以通过最大程度地测量其感官观察和动作的可能性来学习代理的内部模型和奖励功能。 因此，这从代理的行为中提取了代理的理性和可解释的思想。 根据这种行为的理性模型，我们还提供了一个解释神经数据的编码，重新编码和解码的框架。当该方法应用于对自然搜索任务进行次优优化的模拟主体的行为和神经数据时，该方法可成功恢复其内部模型和奖励功能，以及代表任务的神经流形内部的计算动力学。 这项工作为发现大脑如何用动态信念表示和计算奠定了基础。</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>理解大脑如何工作需要解释神经活动。行为主义传统(1)的目的是将大脑理解为一个黑盒子，仅仅从它的输入和输出。现代神经科学已经能够通过观察黑匣子来获得重要的见解，但仍然在很大程度上将神经活动的测量与大脑的输入和输出联系起来。尽管这是感觉神经科学和运动神经科学的基础，但大多数神经活动支持无法解释的计算和认知功能-我们可以将这些功能称为“思想”。要理解大脑的计算，我们应该将神经活动与思想联系起来。 问题是，您如何衡量一个想法？</p><p>在这里，我们建议通过将可解释的人工智能（AI）认知模型（用于自然任务）与对动物的感觉输入和行为输出的测量相结合，将思想建模为动态信念(我们赋予动物的)。我们通过动物世界的相关动态、观察、行动和目标来定义动物的任务。解决这些任务的人工智能模型会生成信念、动力和行动，这些信念、动力和行动反映了解决这些任务所需的基本计算，并生成像动物一样的行为。有了这些估计的想法，我们建议对大脑活动进行分析，以找到可能实现这些想法的神经表示和转换。</p><p>我们的方法在保持认知模型的可解释性的同时，结合了复杂神经网络模型的灵活性。它超越了黑盒神经网络模型，它可以解决一项特定任务并找到与大脑的表征相似性（2-4）。 相反，我们解决了整个任务系列，然后找到最能描述动物行为任务的解决方案。然后，我们将这项最匹配的任务的属性与动物的心理模型关联起来，并称其为“理性”，因为在这种内部模型下，这样做是正确的。我们的方法基于潜在的潜在变量动力学来解释行为和神经活动，但是它对神经活动的常规潜在变量方法进行了改进，该方法仅压缩数据而无需考虑任务或计算（5,6）。相反，我们的潜在变量从任务本身和动物的信念中根据其内部模型继承意义。这为我们的行为和神经模型提供了可解释性。</p><p>我们还想确保我们能在自然任务中解释底层生态行为的关键神经计算。 我们可以通过使用具有关键属性（确保我们的模型解决方案能够实现这些神经计算）的任务来完成此任务。首先，自然的任务应该包括潜在的或隐藏的变量：动物不直接对他们的感觉数据采取行动，因为这些数据只是对隐藏的现实世界的间接观察（7）。 其次，该任务应涉及不确定性，因为现实世界中的感知数据从根本上是模棱两可的，并且在根据其可靠性对证据进行权衡时行为会有所改善。第三，潜在变量与感官证据之间的关系在任务中应该是非线性的，因为如果线性计算就足够了，那么动物就不需要大脑了：它们只需将传感器连接到肌肉上，就可以一步计算出相同的结果。 第四，任务应该具有相关的时间动态，因为行动会影响未来，世界的有用特性也会改变。 动物必须对此负责。</p><p>尽管动物每天执行的自然任务确实具有这些属性，但大多数神经科学研究为了简单起见将它们的子集分离出来。 尽管这揭示了神经计算的重要方面，但它也有可能错过了大脑计算的一些基本结构。 最近的进展保证了任务和模型的自然性和复杂性。</p><p>随着复杂性和自然性的增加，对实际研究的一个主要挑战是从许多神经元记录足够的空间和时间精度，以揭示这些任务的相关计算动力学。具体来说，神经数据的维数必须大于目标任务的维数（8）。 现代神经技术现在为我们提供了这个机会：以细胞分辨率进行全脑钙成像以及细粒度的电生理记录可以同时从数千个神经元中进行高频记录。有限的实验时间和覆盖范围仍然阻碍了我们探索神经表征的能力。 但是，利用当前的大规模神经数据，我们将越来越有足够的能力来寻找自然主义和认知上有趣的任务中的神经表示和动力学。</p><p>本文通过提供估计思想和解释神经活动的方法，在理解大脑如何产生复杂行为方面取得了进展。 我们首先描述一种基于模型的技术，我们称其为“逆向理性控制”，用于推断可能是理性思想基础的潜在动力学。 然后，我们提供了有关神经编码的理论框架，该框架展示了如何使用这些估算的理性思想来构建可解释的神经动力学描述。</p><p>我们通过分析由人工大脑执行的任务来说明这些贡献，并展示了如何检验以下假设：神经网络具有与任务相关的变量的隐式表示，这些变量可用于解释神经计算。 我们选择与生态相关的觅食任务，该任务需要对过去的奖励，当前的观察和内部记忆状态保持敏感。 我们的方法应作为解释执行自然主义任务的真实行为者的行为和大脑活动的宝贵工具。</p><h1 id="成果"><a href="#成果" class="headerlink" title="成果"></a>成果</h1><p>，<br><strong>将行为建模为理性的。</strong> 在一个不确定且部分可观察的环境中，动物学习基于有限的感官信息和主观价值来计划和采取行动。 为了更好地理解这些自然行为并解释其神经机制，估计解释动物行为策略的内部模型和奖励功能将是有益的。 在本文中，我们将动物建模为理性行为主体，它们以最佳方式发挥作用，以最大化其自身的主观回报，但这是在一个关于世界的可能不正确的假设下进行的。然后，我们将这个模型反转以推断出主体的内部假设和报酬，并估算内部信念的动态。 我们称此方法为反向理性控制（IRC），因为我们可以推断出解释主体控制其环境的次优行为的原因。</p><p>该方法为主体的观察和行动轨迹创建概率模型，并选择模型参数（这个轨迹的最大似然）。 我们对代理人的内部模型进行假设，即认为它会获得关于根据已知随机动力学演化的世界的不可靠的感官观察。 最后，我们假设选择代理的行为是为了最大化其主观预期的长期效用。该效用既包括诸如食物奖励之类的收益，也包括诸如行动所消耗的能量之类的成本；它还应该考虑描述动机的内部状态，如饥饿或疲劳，这些主观状态调节主观效用。 然后，我们使用代理人的观察和动作序列来了解这个内部模型在世界（环境）范围内的参数。</p><p>如果没有模型，则无法同时推断出奖励和潜在动力学，从而导致许多退化的解决方案。但是，在合理的模型约束下，我们证明了可以识别代理商的奖励功能和假定的动力学。 我们学习到的参数包括代理商假定的世界变量的随机动态，对那些世界状态的感官观察的可靠性以及对行为相关成本和状态相关奖励的主观权重。</p><p><strong>部分可观察的马尔可夫决策过程。</strong></p><p><strong>逆向理性控制。</strong>尽管具有最佳吸引力，但动物很少在实验确定的任务中表现出最佳，而不仅仅是表现出更多的随机性。 缺乏最优性，关于动物的行为我们可以有什么原则性的指导来帮助我们理解其大脑？ 一种可能性是动物是“理性的”，即与被测动物相比，最适合于不同的环境。在这一节中，我们提出了一种基于行为（主体在这个意义上是理性）的可能性的行为分析。其核心思想是通过任务来参数化一个主体可能的策略，在这些任务下，每个任务都是最优的，并找出这些任务中哪个最能解释行为数据。</p><p>我们指定了一个POMDP系列，其中每个成员都有自己的任务动态，观察概率和主观奖励，共同构成参数矢量θ。 这些不同的任务将产生相应的最佳代理族，而不是单个最佳代理。 然后，根据实验观察到的数据并根据特工的潜在信念将其边缘化（图1B），我们以此家庭中的任务定义对数可能性：<br>$$L(\theta)=log\int db_{1:T} p(b_{1:T},o_{1:T},a_{1:T},s_{1:T}|\theta, \phi)$$<br>换句话说，我们发现了代理最佳解决任务的可能性。 在[3]φ中，实验设置中的已知参数决定了世界动态。 由于它们仅影响图形模型中的观测量，因此不会影响模型似然度θ（补充信息）。</p><p>这种数学结构将可解释的模型直接连接到实验可观察的数据。 现在，我们可以形式化行为神经科学中的重要科学问题。 例如，如下所述，我们可以最大程度地在模型类中找到对动物行为的最佳解释性解释。 我们还可以比较归类为代理的不同奖励类型或关于任务的假设的不同模型类。</p><p>对数似然[3]似乎很复杂，因为它取决于观察和行动的整个顺序，并且需要对潜在信念进行边缘化。 尽管如此，它仍可以使用POMDP的Markov属性进行计算：动作和观察可建立一个Markov链，其中代理的信念状态是一个隐藏变量。 我们证明了可以利用这种结构来有效地计算这种可能性（补充信息）。</p><p><strong>行为合理化的挑战和解决方案。</strong>要解决IRC问题，我们需要对任务，信念和策略进行参数化，然后需要优化参数化对数可能性，以找到对数据的最佳解释。 这提出了我们需要解决的实际挑战。我们解释行为的核心思想是根据任务参数化一切。 最后，我们模型的所有其他元素都将回溯到这些任务。 因此，信念和过渡是潜在任务变量上的分布，策略表示为任务参数和偏好的函数，对数似然率是假设代理假设的任务参数的函数。</p><p>因此，无论我们用于信念空间或策略的任何表示形式，我们都需要能够通过这些表示形式对任务参数传播优化。 这是IRC实际解决方案的要求。 第二个要求是我们可以实际计算最佳策略。</p><p>由于概率空间远远大于它所度量的状态空间，因此很难有效地表示一般的信念和转换。信念状态是一种概率分布，因此即使是离散的世界状态也具有连续的值。对于连续变量，概率空间可能是无限维的。这对机器学习和大脑都是一个巨大的挑战，并且发现不确定性的神经似是而非的表现形式是一个活跃的研究课题(12－17)。我们考虑两个简单的方法来解决IRC使用有损压缩的信念:离散化，或分布近似。然后给出了离散情况下的具体应用实例。</p><p>离散的信念和行动。如果我们有一个离散的状态空间，那么我们可以使用传统的马尔可夫决策策略。对于足够小的世界空间，我们可以完全离散化整个置信空间，然后使用标准MDP算法解决置信MDP问题(11,18)。特别地，可以通过Bellman方程递归地表示softmax策略\({\pi(a|b})\)下的状态作用值函数\({Q(b,a)}\)，我们可以使用值迭代（10,11）进行求解。 然后，结果值函数确定softmax策略\(\pi\)，从而确定对数似然[3]中与策略相关的项。</p><p>最后，为了解决IRC问题，我们可以直接优化这个对数似然，例如通过贪心行搜索(补充信息)。高维问题的另一种选择是使用期望最大值找到具有梯度上升M步的局部最优值（补充信息，（19,20））。 为了计算对数似然的梯度，我们再次使用递归来精确计算值梯度\({\partial Q/\partial \theta}\)，并使用链式规则推导出策略梯度，然后推导出Q辅助函数梯度（补充信息）。</p><p>持续的信念和行动。离散解的计算开销随着问题规模的增大而迅速增长，对于连续状态空间和连续控制变得非常棘手。一个实际的选择是通过一组有限的汇总统计信息来近似后验概率，然后通过期望传播等方法来更新后验概率(21)。 最简单的示例是使用平方统计，即高斯后验。 然后可以根据扩展的卡尔曼滤波器更新此置信状态，该扩展的卡尔曼滤波器考虑了主体的随机非线性动力学内部模型。对于更一般的置信表示，置信更新方程可能需要更多的灵活性。</p><p>采取连续行动进行理性控制还需要我们实施一系列从信念到行动的连续政策π。我们使用深度神经网络通过一个参与者-批评者方法(深度确定性策略梯度，23)来实现这些策略(22)。通过这种方法，一个“批判者”网络可以估算“参与者”网络采取的每项行动的价值。</p><p>深度学习方法通​​常用于强化学习中以提供灵活性，但它们缺乏可解释性：有关策略的信息分布在网络的权重和偏见中。 至关重要的是，为了保持可解释性，我们通过任务将这个族参数化。 具体来说，我们将模型参数作为策略网络的附加输入，并在任务参数\({p(\theta)}\)（22）的先前分布上同时学习最佳策略。这使得网络可以在任务族的POMDPs之间泛化其最优策略。它还允许我们简单地使用自动微分来计算策略梯度，这在优化对数可能性时会利用该差异来找到最适合代理行为的参数。</p><p>最终，在针对离散或连续表示优化对数似然后，最终结果是一组参数θ，可以最好地解释观察到的行为数据，并定义代理的假定内部任务模型和主观偏好。在此模型类中，我们因此找到了对代理人行为的最佳理性解释。</p><p><strong>为理性思维寻找神经代码。</strong>我们不认为任何真实的大脑都会明确地计算出Bellman方程的解，而是通过结合经验和思维模型来学习策略。 经过足够的训练，结果是一个代理人的行为“好像”在解决POMDP（图２Ａ）。</p><p>如果像我们在“逆向理性控制”中假设的那样，将动物的行为很好地描述为取决于潜在的信念，那么就应该在大脑中找到这些信念的神经关联。 如果我们能找到这样的相关性，这是否意味着神经元编码或代表了这些信念？ 有人认为，神经密码的概念是一个较差的隐喻，因为它既不捕捉大脑的因果或机械结构，也不捕捉其与行动和能力的关系（24-26）。例如，可能是大脑没有利用神经信号，而神经学家可以利用这些信号来提取有关某项任务的信息。</p><p>相反，这里我们认为编码、重新编码和解码的关联过程可以在算法或表征层面上解释大脑中与任务相关的计算(27)。大脑的编码指定了如何使用神经活动来估计任务变量(图2B)，既包括奖励变量，也包括不相关或讨厌的变量，这些变量必须与它们分开。重新编码描述了如何通过神经处理在时间和空间上转换编码(图2C)。解码描述了这些评估如何预测未来的行动(图2D)。</p><p>（在我们使用这些术语时，我们是从大脑的角度出发的。“解码”一词更多地反映了科学家的观点，即科学家解码大脑活动以估计编码质量。相反，我们用“解码”这个术语来描述神经活动是如何影响行为的:我们说大脑解码自己的活动来产生行为。）</p><p>这种层次的解释不需要捕捉神经反应的每一个方面，也不需要捕捉它们进化的机制。显然，它不能解释对未经测试的任务变量的响应。尽管如此，如果我们能在一个任务相关的子流形(28)中解释刺激和动作依赖的神经动力学，这将是一个巨大的进步，它解释了信息是如何相互作用和预测行为的。尽管这种“假设”描述不能合法地声称是因果关系，但由于它确实为因果关系测试提供了有用的预测，说明哪些神经特征会影响计算和行为，因此可以提升为因果关系（29，30）</p><p>接下来，我们描述这种表示层解释的一般结构。 然后，我们采用这种方法来分析人工大脑执行特定的觅食任务。</p><p>为了开始分析，我们建议使用逆理性控制从我们观察到的行为者做出的感觉输入和动作中构建行为模型。 推断的内部模型使我们能够估算出主体关于部分观察到的世界状态ｓ的时间依赖性信念b。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Neuroscience</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用卷积神经网络图像分类的技巧包</title>
    <link href="/2019/10/18/tricks/"/>
    <url>/2019/10/18/tricks/</url>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><a id="more"></a><h1 id="3-有效训练"><a href="#3-有效训练" class="headerlink" title="3 有效训练"></a>3 有效训练</h1><h2 id="3-1-大批次训练"><a href="#3-1-大批次训练" class="headerlink" title="3.1 大批次训练"></a>3.1 大批次训练</h2><h3 id="线性缩放学习率"><a href="#线性缩放学习率" class="headerlink" title="线性缩放学习率"></a>线性缩放学习率</h3><p>在使用小批次进行随机数据的训练，增加数据批次没有改变随机梯度的期望而减少了方差。换一句话说，一个大批次大小减少梯度的噪音。因此我们可以提高学习率，以沿梯度方向的相反方向获得更大的改进。<strong>特别，如果我们遵循ResNet原论文中的对于批次大小为256时，初始学习率设置成0.1。然后，当改变一个更大的批次大小为b，我们将增加初始学习率为0.1×b/256.</strong></p><h3 id="学习率预热"><a href="#学习率预热" class="headerlink" title="学习率预热"></a>学习率预热</h3><p>在训练的开始，所有的参数通常是随机值，因此离最终的解决方案很远。使用过大的学习率可能会导致数值不稳定。在热身启发式中，我们在开始时使用一个小的学习速率，然后在训练过程稳定时切换回初始的学习速率。Goyalet al.[7]提出了一种渐进热身策略，<strong>将学习率从0线性增加到初始学习率。换句话说，假设我们将使用前m个批次（例如5个数据周期）进行预热，并且初始学习率为η，那么在第i批次中，1≤i≤m，我们将学习率设为iη\m。</strong></p><h3 id="Zero-gamma"><a href="#Zero-gamma" class="headerlink" title="Zero  gamma"></a>Zero  gamma</h3><p>ResNet结构：一个ResNet网络由多个残差块组成，每个残差块由几个卷积层组成。给定输入x，假设block(x)是block的最后一层的输出，这个残差块将输出x + block(x)。注意，block的最后一层可以是批处理标准化(BN)层。</p><p>Batch Normalization：BN层首先标准化其输入，用\(\check{x} \)表示，然后执行一个尺度变换：\({\gamma \check{x} + \beta} \)。γ和β都是可学习的参数，其元素分别初始化为1s和0s。</p><p>zero \(\gamma \)技巧：我们对位于残差块末尾的所有BN层初始化γ= 0。 结果：所有残差块仅返回其输入，模拟网络在初始阶段具有较少的层数，更容易训练。</p><h3 id="没有bias衰减"><a href="#没有bias衰减" class="headerlink" title="没有bias衰减"></a>没有bias衰减</h3><p>权重衰减（weight decay）：权值衰减通常应用于所有可学习的参数，包括权重和偏差。这相当于对所有参数应用L2正则化，使它们的值趋近于0。</p><p>改进：Jia等人指出的只对权重应用正则化，来避免过拟合。</p><p>技巧：将权重衰减应用于卷积层和完全连接层中的权重，对偏差不进行衰减。其他参数，包括BN层中的biases以及γ和β，均未调整。</p><p>大批次的使用情况：（Large batch training ofconvolutional networks with layer-wise adaptive rate scaling）论文提出分层的自适应学习率，据报告对于超大批量（超过16K）有效。将自身限于能够进行单机训练的情况下，每批不超过2K的批次通常会带来良好的系统效率。</p><h2 id="3-2-低精度训练（数值精度类型、数值位数）"><a href="#3-2-低精度训练（数值精度类型、数值位数）" class="headerlink" title="3.2 低精度训练（数值精度类型、数值位数）"></a>3.2 低精度训练（数值精度类型、数值位数）</h2><p>如何加快训练速度：神经网络通常采用32位浮点(FP32)精度进行训练。也就是说，所有的数字都以FP32格式存储，算术运算的输入和输出也是FP32数字。NvidiaV100在FP32中提供14 TFLOPS，但在FP16中提供100 TFLOPS。在V100上从FP32切换到FP16后，整体训练速度提高了2到3倍。（这里根据自己实验设备而定。）</p><p>存在的问题：尽管性能有所提高，但降低的精度会缩小范围，使结果更可能超出范围，进而干扰训练进度。</p><p>解决方案：（1）Micikeviciusetal建议在FP16中存储所有参数和激活，并使用FP16计算梯度。同时，FP32中的所有参数都有一个副本，用于参数更新。（2）将标量与损失（loss）相乘以更好地将梯度范围对齐到FP16。</p><h2 id="3-3-实验结果"><a href="#3-3-实验结果" class="headerlink" title="3.3 实验结果"></a>3.3 实验结果</h2><p><img src="/assets/tricks/table_3.png" srcset="/img/loading.gif" alt="表3.ResNet-50在基线(BS=256, FP32)和更高效的硬件设置(BS=1024, FP16)之间的训练时间和验证精度的比较。"><br><img src="/assets/tricks/table_4.png" srcset="/img/loading.gif" alt="表4. 在ResNet-50上，有效训练中每种启发式方法的分解效果。"></p><ul><li><p>训练时间减少：与批量大小为256和FP32的基线相比，使用更大的1024批量大小和FP16可以将ResNet-50的训练时间从每个epoch 13.3分钟减少到4.4分钟。</p></li><li><p>叠加训练技巧提高精度：通过堆叠所有启发式方法进行大批量训练，与基线模型相比，使用1024批大小和FP16训练的模型甚至稍微提高了0.5％的top-1准确性。</p></li><li><p>实验结果：表4中显示了所有启发式方法的消融研究，仅通过线性缩放学习率将批次大小从256增加到1024会导致top-1准确性降低0.9％，同时堆叠其余三个启发式方法可以弥补这一差距。在训练结束时从FP32切换到FP16不会影响准确性。</p></li></ul><h1 id="4-模型调整"><a href="#4-模型调整" class="headerlink" title="4 模型调整"></a>4 模型调整</h1><h2 id="4-1-ResNet结构"><a href="#4-1-ResNet结构" class="headerlink" title="4.1 ResNet结构"></a>4.1 ResNet结构</h2><p><img src="/assets/tricks/figure_1.png" srcset="/img/loading.gif" alt="图1. ResNet-50网络结构"><br>ResNet网络结构：（如图1所示），ResNet网络由输入主干，四个后续阶段和最终输出层组成。<br>（1）输入主干具有步长为2，输出通道为64，卷积核为7×7的卷积层，紧接着应用步长为2，核为3×3的池化层。输入主干将输入宽度和高度减少4倍，并将其通道大小增加到64。</p><p>（2）从阶段2开始，每个阶段都从一个降采样块（down sampling block）开始，然后是几个残差块（residual block）。在下采样块中，有路径A和路径B。</p><ul><li>路径A有三个卷积层，其卷积核大小分别为1×1,3×3和1×1。第一个卷积的步长为2，可将输入宽度和高度减半；最后一个卷积的输出通道是前两个卷积的输出通道的4倍，这称为瓶颈结构（bottleneck block）。</li><li>路径B使用步长为2的1×1卷积将输入形状转换为路径A的输出形状，因此可以将两条路径的输出求和以获得下采样块的输出。</li></ul><p>（3）残差块类似于下采样块，除了仅使用步长为1的卷积。</p><p>（4）可以在每个阶段改变残差块的数量，得到不同的ResNet模型。如ResNet18,ResNet50,ResNet152。</p><h2 id="4-2-ResNet调整"><a href="#4-2-ResNet调整" class="headerlink" title="4.2. ResNet调整"></a>4.2. ResNet调整</h2><p>ResNet-B，ResNet-C是已经提出的调整。论文提出的调整方案是ResNet-D</p><h3 id="ResNet-B"><a href="#ResNet-B" class="headerlink" title="ResNet-B"></a>ResNet-B</h3><p><img src="/assets/tricks/figure_2.png" srcset="/img/loading.gif" alt="图2. 3种ResNet调整。Resnet - B修改了ResNet的下采样块。ResNet-C进一步修改输入主干。在此之上，ResNet-D再次修改向下采样块。"></p><p>原因：它改变了ResNe的下采样块。实验观察到，路径A中的卷积忽略了输入特征图的四分之三，因为它使用的卷积核大小为1×1，步长为2。</p><p>改进：如图2a所示，ResNet-B改变路径A中前两个卷积的步长大小，所以没有信息被忽略。因为第二层卷积的卷积核大小为3×3，因此路径A的输出形状保持不变。</p><h3 id="ResNet-C"><a href="#ResNet-C" class="headerlink" title="ResNet-C"></a>ResNet-C</h3><p>出处：此调整最初是在Inception-v2中提出的，可以在其他模型的实现中找到，例如SENet [12]，PSPNet [31]，DeepLabV3 [1]和ShuffleNetV2 [21]。</p><p>原因：观察发现，卷积的计算成本是核宽度或高度的平方。一个7×7卷积比3×3卷积贵5.4倍。</p><p>改进：图2b所示。此调整将输入主干的7×7卷积替换为三个保守的3×3卷积，其中第一个和第二个卷积的输出通道为32，步长为2，而最后一个卷积使用64输出通道。</p><h3 id="ResNet-D"><a href="#ResNet-D" class="headerlink" title="ResNet-D"></a>ResNet-D</h3><p>原因（创新点）：受ResNet-B的启发，我们注意到下采样块路径B中的1×1卷积也忽略了3/4个输入特征图，我们想对其进行修改，因此不会忽略任何信息。</p><p>改进：根据经验，我们发现在卷积之前添加一个步长为2的2×2平均池化层（卷积层的步长更改为1）在实践中效果很好，并且对计算成本的影响很小。</p><h2 id="4-3-实验结果"><a href="#4-3-实验结果" class="headerlink" title="4.3. 实验结果"></a>4.3. 实验结果</h2><p><img src="/assets/tricks/table_5.png" srcset="/img/loading.gif" alt="表5. 将ResNet-50与模型大小，FLOP和ImageNet验证准确性的三个模型调整进行比较。"><br>实验方案：使用第3节中描述的三种调整和设置来评估ResNet-50，即批量大小为1024，精度为FP16。结果如表5所示。</p><p>实验结果：<br>（1）与ResNet-50对比，ResNet-B在下采样块的路径A中可以接收到更多信息，其验证准确性提高了约0.5％。<br>（2）将7×7卷积替换为三个3×3卷积可进一步提高0.2％。在下采样块的路径B中可获的更多信息，可将验证准确度再提高0.3％。</p><p>结论：ResNet-50-D将ResNet-50提升了1％。</p><p>计算成本对比：四个模型具有相同的模型大小。ResNet-D具有最大的计算成本，但就浮点运算而言，它与ResNet-50的差异在15%以内。实际上，我们观察到，与ResNet-50相比，ResNet-50-D在训练吞吐量方面仅慢3%。</p><h1 id="5-训练改进"><a href="#5-训练改进" class="headerlink" title="5 训练改进"></a>5 训练改进</h1><p>在本节中，我们将描述四个训练改进，来进一步提高模型的准确性。</p><h2 id="5-1-余弦学习率衰减（Cosine-learning-rate-decay）"><a href="#5-1-余弦学习率衰减（Cosine-learning-rate-decay）" class="headerlink" title="5.1. 余弦学习率衰减（Cosine learning rate decay）"></a>5.1. 余弦学习率衰减（Cosine learning rate decay）</h2><p>来源： Loshchilov（论文：SGDR: stochastic gradient de-scent with restarts）提出一个余弦退火策略。</p><p>cosine decay：一个简化的版本是根据余弦函数将学习率从初始值降低到0。假设批次总数为T（忽略预热阶段），则在批次t处，学习率\(\eta_t\)计算为：\({\eta_t = \frac{1}{2} (1 + cos(\frac{t\pi}{T}))\eta }\)。其中\(\eta \)是初始学习率。</p><p>cosine decay 和 step decay的对比（图3a）：</p><ul><li>cosine decay：余弦衰减在开始时缓慢降低学习速度，然后在中间时几乎呈线性下降，在结束时再次减慢。</li><li>与step decay相比：余弦衰减从一开始就对学习进行衰减，但在step decay使学习速率降低10倍之前，余弦衰减仍然很大，这可能会提高训练的进度。 </li></ul><h2 id="5-2-标签平滑（Label-Smoothing）"><a href="#5-2-标签平滑（Label-Smoothing）" class="headerlink" title="5.2. 标签平滑（Label Smoothing）"></a>5.2. 标签平滑（Label Smoothing）</h2><h3 id="标签的常用使用过程"><a href="#标签的常用使用过程" class="headerlink" title="标签的常用使用过程"></a>标签的常用使用过程</h3><ul><li><p>标签预测置信度分数-&gt;softmax预测概率：图像分类网络的最后一层通常是一个全连通层，隐藏的大小等于标签的数量，用K表示，用来输出预测的置信度分数。给定一张图像，用\(z_i\)表示第\(i\)类的预测分数。这些分数可以通过softmax函数进行归一化得到预测概率。用q表示softmax运算符q = softmax(z)的输出，i类的概率qi可以通过下式计算：<br>$$<br>q_i = \frac{exp(z_i)}{\sum_{j=1}^{K} exp(z_j)}<br>$$<br>这是很容易看出\({q_i &gt; 0}\)，并且\({\sum_{j=1}^{K} q_i = 1}\)，所以q是一个合理的概率分布。</p></li><li><p>对标签设置成one-hot向量形式：假设图像的真实标签为y，则如果i = y，则将真实概率分布构造为pi = 1，否则将其构造为0。在训练期间，通过最小化负交叉熵损失来更新模型参数，以使这两个概率分布彼此相似。特别地，通过p的构造方式，我们知道\(l(p,q) = -logp_y = -z_y + log(\sum_{i=1}^{K} exp(z_i)) \),最佳解决方案是\(z_y^* = \) inf，同时保持其他大小足够小。换句话说，它鼓励显著不同的输出得分，这可能导致过度拟合。</p></li></ul><h3 id="标签平滑"><a href="#标签平滑" class="headerlink" title="标签平滑"></a>标签平滑</h3><ul><li>起源：标签平滑的思想首先被提出用于训练Inceptionv2。它改变了真实概率的构造为<br>$$<br>q_i=\begin{cases}<br>1-\epsilon,\quad if \quad i=y \\<br>\epsilon / (K-1),\quad otherwise,<br>\end{cases}<br>$$<br>其中\(\epsilon\)是一个小常数。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>image classification</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Res2Net</title>
    <link href="/2019/09/27/Res2Net/"/>
    <url>/2019/09/27/Res2Net/</url>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="Res2Net-一种新的多尺度的骨干架构"><a href="#Res2Net-一种新的多尺度的骨干架构" class="headerlink" title="Res2Net 一种新的多尺度的骨干架构"></a>Res2Net 一种新的多尺度的骨干架构</h1><h3 id="摘要-在众多视觉任务中，多尺度表征特征具有重要意义。近年来，中枢卷积神经网络-CNNs-的发展不断显示出更强的多尺度表示能力，从而在广泛的应用中获得一致的性能提升。然而，大多数现有的方法以分层的方式表示多尺度特性。在本文中，我们提出了一种新的CNNs构建块，即Res2Net，通过在一个残差块内构造类残差的分层连接。Res2Net代表了粒度级别的多尺度特性，并增加了每个网络层的接受域范围。建议的Res2Net块可以插入到最先进的CNN骨干模型，例如，ResNet，ResNeXt，和DLA。我们在所有这些模型上对Res2Net块进行了评估-并在广泛使用的数据集上显示与baselinemodels一致的性能提升，例如。cifar-100和ImageNet。计算机视觉任务的进一步模型简化测试和实验结果，对象检测、类激活映射-CAM-和显著性物体-SOD-检测，进一步验证了theRes2Net相对于最先进的基线方法的优越性。源代码和训练的模型可以在https-mmcheng-net-res2net-找到"><a href="#摘要-在众多视觉任务中，多尺度表征特征具有重要意义。近年来，中枢卷积神经网络-CNNs-的发展不断显示出更强的多尺度表示能力，从而在广泛的应用中获得一致的性能提升。然而，大多数现有的方法以分层的方式表示多尺度特性。在本文中，我们提出了一种新的CNNs构建块，即Res2Net，通过在一个残差块内构造类残差的分层连接。Res2Net代表了粒度级别的多尺度特性，并增加了每个网络层的接受域范围。建议的Res2Net块可以插入到最先进的CNN骨干模型，例如，ResNet，ResNeXt，和DLA。我们在所有这些模型上对Res2Net块进行了评估-并在广泛使用的数据集上显示与baselinemodels一致的性能提升，例如。cifar-100和ImageNet。计算机视觉任务的进一步模型简化测试和实验结果，对象检测、类激活映射-CAM-和显著性物体-SOD-检测，进一步验证了theRes2Net相对于最先进的基线方法的优越性。源代码和训练的模型可以在https-mmcheng-net-res2net-找到" class="headerlink" title="摘要-在众多视觉任务中，多尺度表征特征具有重要意义。近年来，中枢卷积神经网络(CNNs)的发展不断显示出更强的多尺度表示能力，从而在广泛的应用中获得一致的性能提升。然而，大多数现有的方法以分层的方式表示多尺度特性。在本文中，我们提出了一种新的CNNs构建块，即Res2Net，通过在一个残差块内构造类残差的分层连接。Res2Net代表了粒度级别的多尺度特性，并增加了每个网络层的接受域范围。建议的Res2Net块可以插入到最先进的CNN骨干模型，例如，ResNet，ResNeXt，和DLA。我们在所有这些模型上对Res2Net块进行了评估,并在广泛使用的数据集上显示与baselinemodels一致的性能提升，例如。cifar - 100和ImageNet。计算机视觉任务的进一步模型简化测试和实验结果，对象检测、类激活映射(CAM)和显著性物体(SOD)检测，进一步验证了theRes2Net相对于最先进的基线方法的优越性。源代码和训练的模型可以在https://mmcheng.net/res2net/.找到"></a><strong>摘要</strong>-在众多视觉任务中，多尺度表征特征具有重要意义。近年来，中枢卷积神经网络(CNNs)的发展不断显示出更强的多尺度表示能力，从而在广泛的应用中获得一致的性能提升。然而，大多数现有的方法以分层的方式表示多尺度特性。在本文中，我们提出了一种新的CNNs构建块，即Res2Net，通过在一个残差块内构造类残差的分层连接。Res2Net代表了粒度级别的多尺度特性，并增加了每个网络层的接受域范围。建议的Res2Net块可以插入到最先进的CNN骨干模型，例如，ResNet，ResNeXt，和DLA。我们在所有这些模型上对Res2Net块进行了评估,并在广泛使用的数据集上显示与baselinemodels一致的性能提升，例如。cifar - 100和ImageNet。计算机视觉任务的进一步模型简化测试和实验结果，对象检测、类激活映射(CAM)和显著性物体(SOD)检测，进一步验证了theRes2Net相对于最先进的基线方法的优越性。源代码和训练的模型可以在<a href="https://mmcheng.net/res2net/.找到" target="_blank" rel="noopener">https://mmcheng.net/res2net/.找到</a></h3><h3 id="索引词-多尺度，深度学习。"><a href="#索引词-多尺度，深度学习。" class="headerlink" title="索引词-多尺度，深度学习。"></a><strong>索引词</strong>-多尺度，深度学习。</h3><h2 id="1-导论"><a href="#1-导论" class="headerlink" title="1.导论"></a><strong>1.导论</strong></h2><p>如图1所示，视觉模式在自然场景中以多尺度出现。首先，物体可能以不同的大小出现在一张图像中，例如，沙发和杯子大小不同。其次，一个对象的基本上下文信息可能占据比对象本身更大的区域。例如，我们需要依靠大桌子作为背景来更好地辨别放在上面的小黑点是杯子还是笔架。最后，从不同的尺度感知信息对于理解零件以及用于细粒度分类和语义分割等任务的对象是必不可少的。因此，为视觉认知任务的多尺度刺激设计好的特征至关重要，包括图像分类、对象检测、注意力预测、目标跟踪、动作识别、语义分割、显著对象检测、对象提议、骨架提取、立体匹配和边缘检测。不出所料，多尺度特征已经广泛应用于传统特征设计和深度学习。在视觉任务中获得多尺度表示需要特征提取器使用大范围的接受域来以不同的尺度描述对象/部分/上下文。卷积神经网络(CNNs)通过一堆卷积运算符自然地学习从粗到精的多尺度特征。中枢神经系统固有的多尺度特征提取能力导致了解决众多视觉任务的有效表示。如何设计更高效的网络架构是进一步提高CNNs性能的关键。</p>]]></content>
    
    
    
    <tags>
      
      <tag>image classification</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度炼丹之路--one day</title>
    <link href="/2019/09/25/refining_dan/"/>
    <url>/2019/09/25/refining_dan/</url>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><blockquote><p>本周主要做了三个任务：<br>1、准备竞赛：调试网络结构以更好的识别河道污染<br>2、学习深度卷积生成对抗网络并进行相应的实验<br>3、调试嵌入式对安全帽的目标检测任务</p></blockquote><a id="more"></a><h1 id="竞赛任务"><a href="#竞赛任务" class="headerlink" title="竞赛任务"></a>竞赛任务</h1><h2 id="任务进展"><a href="#任务进展" class="headerlink" title="任务进展"></a>任务进展</h2><p>本次竞赛的课题任务是使用深度学习对给出的河道图片进行分类，可以检测出最常见的河道污染、水污染及垃圾污染。</p><p>竞赛给出的数据集分为有标注的训练集（有监督学习）和没有标注信息的测试集。训练集的数据只有2200张，样本过于小，所以很容易造成模型过拟合，这也是本次竞赛的隐藏的难点。还有，测试集没有标注信息，也就是在训练的时候，没法进行评估。只能单从训练数据上看出模型的损失下降和准确度情况，但这样不容易把控模型的拟合能力。</p><p>本次给出了四种类别污染图片，分为waterpollute（水污染），garbage（河流垃圾），health（健康河流），others（其他污染）。在这里有一个问题，也是最新的研究方向。对于每个类别的图片是否存在不平衡现象，由于本次竞赛数据集不公开，所以无法得知。但是，对于类别不平衡对模型训练的泛化能力是否有影响，需要进一步进行文献的阅读。</p><p>下面阐述本次实验的结果：</p><p>一、第一次提交</p><ul><li>本次使用了ResNet残差神经网络来训练检测河道污染图片的模型，网络层级达到了50层。最终提交结果到竞赛平台上获得0.6955的成绩，排名为13，但是和前面六名只相差0.2的点。所以，可以进行进一步的改进。这里的评估标准是使用了F1值，即召回率和精确率的平均。</li><li>为了解决过拟合的问题，这里应用了迁移学习（transfer learning），即将源数据集上学习到的知识迁移到目标数据集上。正如，本次竞赛的数据集，虽然ImagNet数据集和河道图片大都无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状及物体组成等。这些类似的特征对河道图片同样有效。</li><li>另外还可以对数据集进行数据增广的预处理操作来缓解样本太少引起的过拟合问题。本次只使用了随机翻转预处理操作，对所有训练样本按一定概率进行翻转，经过一定周期的迭代训练，变相的增加了数据集。</li><li>模型训练过程，一开始只是按照类似在其他cifar-10数据集上进行一些网络模型训练的参数设置，初始批次设置成32，学习率设置成0.01，优化算法使用AdaM算法，此算法不但使用动量作为参数更新方向，而且可以自适应调整学习率。但是在进行训练时，损失一直在震荡，一开始我认为AdaM优化算法可能不适合本次训练，换成SGD后并正常的下降了。现在细想想是自己对AdaM算法了解的不够，所以在设置参数时除了问题。损失函数使用标准的交叉熵损失。因为，使用了迁移学习，其实训练过程是个微调过程，我主要训练的应该是网络的最后一层，也就是输出层。但是，由于对迁移学习的了解太过浅层，所以只是将原先预训练的输出层进行一个简单的变换，也就是输出相应类别。这里，我又忽视了一点。网络预测的值包含了负值，也就只输出每个类的分布情况，而不是以一定的概率进行分布。所以在最后和标签进行对比时，结果很不理想。所以，后来我对输出结果使用了softmax，使输出结果分布在0-1的范围。</li></ul><p>二、第二次提交</p><ul><li>本次结合第一次实验中的问题进行了一些修改。第一次实验的最终的结果不是很高，我的想法可能是由于网络的层级过于深，再加上训练样本过于少，造成训练的时候拟合能力特别强。所以，选用了深度较浅的ResNet18进行实验测试。但是，我忽视了数据集的具体情况。在这四种类别中，那个others类别中的图片比较复杂，在每张图片中主要特征都是比较复杂的特征，但是其也包含了另外三种类别中的主要特征。例如，在others中有张图片中一位消防战士在干净的河流中进行救援。这里主要特征是消防战士，次要特征是干净河流。所以，较浅的网络获得感受野不大，很难识别出others图像。经过实验发现，最后输出的结果没有包含others结果图片。</li><li>经过了解迁移学习的微调操作，对最后输出层的参数进行了随机初始化操作，使得在训练过程之初，不会使训练损失幅度差距太大。由于我主要训练的是最后一层，所以最后一层的学习率一开始需要设置的较大，其它层相对较小。因为，在很大的ImageNet数据集上进行预训练，参数已经足够好。因此，一般选用较小的学习率来微调这些参数。而输出层的随机初始化参数一般需要更大的学习率从头训练。</li><li>本次额外增加了随机增加图片亮度，对比度，饱和度等预处理操作，但是由于网络层太浅，获得的感受野不大，无法提高最终结果成绩，最终结果是0.6344。</li></ul><p>三、第三次提交</p><ul><li>本次实验继承了第二次的输出层参数初始化操作，数据增广技术。恢复网络结构为第一次的ResNet50。但是，最终实验结果是比第一次低了0.03点。</li></ul><p>下一步研究方向：</p><ul><li>增大网络的感受野，尝试更深的网络结构，换用最新的Res2Net网络结构。</li><li>通过实验再详细分析出，为什么others类别的图片给模型操作带来那么大的影响，这种情况在现在有没有一定的研究。</li><li>再重新调试一下训练超参数，换用一下损失函数和优化算法。</li></ul><h1 id="学习深度卷积生成对抗网络"><a href="#学习深度卷积生成对抗网络" class="headerlink" title="学习深度卷积生成对抗网络"></a>学习深度卷积生成对抗网络</h1><p>这里，我只是了解了生成对抗网络的原理。学习的初衷是想能否使用生成对抗网络来生成特定图片，以此解决一些小样本数据过于少的问题。</p><h1 id="生成对抗网络"><a href="#生成对抗网络" class="headerlink" title="# 生成对抗网络"></a># 生成对抗网络</h1><p>2014年发表的一篇论文《Generative Adversarial Networks》包括两部分：</p><ul><li>1、生成网络（generative network）：生成网络生成假数据，并且使假数据尽量显得真实，从而使得鉴别网络误以为生成的数据是真数据。生成网络的输入的数据是随机数，之所以是随机的，是因为生成网络需要生成不同的假数据。若没有随机输入，则生成网络只能生成相同的假数据，不满足应用需求。</li><li>2、鉴别网络（discriminative network）：鉴别网络对生成网络生成的数据进行判别。鉴别网络可以输入真实数据和假数据，以此来识别真假。</li></ul><p>鉴别网络只是用来帮助训练生成网络的，因此，鉴别网络只是在训练过程中使用，不在实际中使用。在训练过程中，生成网络希望鉴别网络不能正确判别出数据的真假，而鉴别网络希望判别数据的真假。</p><p>定义鉴别网络的标签为：</p>]]></content>
    
    
    
    <tags>
      
      <tag>炼丹</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>session(会话)——TensorFlow的运行模型</title>
    <link href="/2019/06/17/tf_placeholder/"/>
    <url>/2019/06/17/tf_placeholder/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文介绍tensorflow中会话的使用方法及参数配置</p></blockquote><a id="more"></a><h2 id="TensorFlow系统结构阐述"><a href="#TensorFlow系统结构阐述" class="headerlink" title="TensorFlow系统结构阐述"></a>TensorFlow系统结构阐述</h2><p>tesorflow分为前端和后端系统。前端系统负责编程模型，构造计算图，后端系统负责运行时的环境、计算图。<br>主要包括四个组件：Client，Distributed Master，Work Service和Kernel Implements。</p><p>（1）Client（客户端）：通过Client可以构建简单或者复杂的计算图，实现各种形式的模式设计。客户端会以Session为接口与后端的Distributed Runtime 中的控制器及多个Worker相连，并启动计算图的执行过程。<br>（2）Distributed Master：分布式控制器，和Session相连的Master（控制器），用于在分布式运行的环境中对一个大的计算图进行拆分。它会根据Session.run()函数的fetches参数，从计算图中反向遍历，找到计算图的子图之后会将该子图再次拆分成多个子图片段。最后，将这些子图片段传递到Work Service，由Work Service启动“子图片段”的执行过程。<br>（3）Work Service：与Session相连的Worker，每个Worker可以与Device Layer中的多个硬件设备相连。对于Master传递过来的“子图片段”，Worker都会按照计算图中节点的依赖关系及当前的设备，调用OP的Kernel实现完成OP操作。<br>（4）Kernel Implement：底层实现接口，是OP在某种硬件设备上的底层实现。<br>TensorFlow分为单机模式和分布式模式。单机模式下只有一个worker，分布式模式下有多个worker。单机模式下将client、master、worker放在一台机器上，分布式模式则视情况放在不同的机器中。</p><h2 id="简单使用会话"><a href="#简单使用会话" class="headerlink" title="简单使用会话"></a>简单使用会话</h2><p>Session类提供run()方法执行计算图，用户给run()方法中传入需要计算的节点和数据，来自动寻找所有需要计算的节点并按依赖顺序执行它们。另外还提供了extend()方法用于添加新的节点和边。</p><p>两种方法使用Session类：<br>（1）通过Session类的Session()构造函数创建会话类实例，通过close()关闭会话释放资源。但是此方法有个缺陷，若程序发生异常而退出时，却没有执行close()方法关闭会话，这会导致资源泄漏。当神经网络过于庞大或者参数量过多时，资源泄漏会是件麻烦的事。<br>（2）使用with/as上下文管理器，当上下文管理器退出时，会自动释放所有的资源。</p><p>下面是方法使用的代码：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<span class="hljs-comment"># 定义常量</span>x = tf.constant([<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], tf.float32, name=<span class="hljs-string">'x'</span>)y = tf.constant([<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>], tf.float32, name=<span class="hljs-string">'y'</span>)<span class="hljs-comment"># 计算两个常量之和</span>result = x + y<span class="hljs-comment"># 定义session</span>sess = tf.Session()<span class="hljs-keyword">with</span> sess.as_default():  <span class="hljs-comment"># 将session设置成默认的</span>    <span class="hljs-comment"># 两种相同计算方法</span>    print(sess.run(result))    print(result.eval(session=sess))    sess.close() <span class="hljs-comment"># 关闭</span><span class="hljs-comment"># 使用InteractiveSession()方法将session已经设置成默认的，不需手动设置。</span>sess = tf.InteractiveSession()print(sess.run(result))<span class="hljs-comment"># 第二种</span><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:    tf.global_variables_initializer().run()    print(sess.run(result))</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>tensorflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>session(会话)——TensorFlow的运行模型</title>
    <link href="/2019/06/17/tf_session/"/>
    <url>/2019/06/17/tf_session/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文介绍tensorflow中会话的使用方法及参数配置</p></blockquote><a id="more"></a><h2 id="TensorFlow系统结构阐述"><a href="#TensorFlow系统结构阐述" class="headerlink" title="TensorFlow系统结构阐述"></a>TensorFlow系统结构阐述</h2><p>tesorflow分为前端和后端系统。前端系统负责编程模型，构造计算图，后端系统负责运行时的环境、计算图。<br>主要包括四个组件：Client，Distributed Master，Work Service和Kernel Implements。</p><p>（1）Client（客户端）：通过Client可以构建简单或者复杂的计算图，实现各种形式的模式设计。客户端会以Session为接口与后端的Distributed Runtime 中的控制器及多个Worker相连，并启动计算图的执行过程。<br>（2）Distributed Master：分布式控制器，和Session相连的Master（控制器），用于在分布式运行的环境中对一个大的计算图进行拆分。它会根据Session.run()函数的fetches参数，从计算图中反向遍历，找到计算图的子图之后会将该子图再次拆分成多个子图片段。最后，将这些子图片段传递到Work Service，由Work Service启动“子图片段”的执行过程。<br>（3）Work Service：与Session相连的Worker，每个Worker可以与Device Layer中的多个硬件设备相连。对于Master传递过来的“子图片段”，Worker都会按照计算图中节点的依赖关系及当前的设备，调用OP的Kernel实现完成OP操作。<br>（4）Kernel Implement：底层实现接口，是OP在某种硬件设备上的底层实现。<br>TensorFlow分为单机模式和分布式模式。单机模式下只有一个worker，分布式模式下有多个worker。单机模式下将client、master、worker放在一台机器上，分布式模式则视情况放在不同的机器中。</p><h2 id="简单使用会话"><a href="#简单使用会话" class="headerlink" title="简单使用会话"></a>简单使用会话</h2><p>Session类提供run()方法执行计算图，用户给run()方法中传入需要计算的节点和数据，来自动寻找所有需要计算的节点并按依赖顺序执行它们。另外还提供了extend()方法用于添加新的节点和边。</p><p>两种方法使用Session类：<br>（1）通过Session类的Session()构造函数创建会话类实例，通过close()关闭会话释放资源。但是此方法有个缺陷，若程序发生异常而退出时，却没有执行close()方法关闭会话，这会导致资源泄漏。当神经网络过于庞大或者参数量过多时，资源泄漏会是件麻烦的事。<br>（2）使用with/as上下文管理器，当上下文管理器退出时，会自动释放所有的资源。</p><p>下面是方法使用的代码：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<span class="hljs-comment"># 定义常量</span>x = tf.constant([<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], tf.float32, name=<span class="hljs-string">'x'</span>)y = tf.constant([<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>], tf.float32, name=<span class="hljs-string">'y'</span>)<span class="hljs-comment"># 计算两个常量之和</span>result = x + y<span class="hljs-comment"># 定义session</span>sess = tf.Session()<span class="hljs-keyword">with</span> sess.as_default():  <span class="hljs-comment"># 将session设置成默认的</span>    <span class="hljs-comment"># 两种相同计算方法</span>    print(sess.run(result))    print(result.eval(session=sess))    sess.close() <span class="hljs-comment"># 关闭</span><span class="hljs-comment"># 使用InteractiveSession()方法将session已经设置成默认的，不需手动设置。</span>sess = tf.InteractiveSession()print(sess.run(result))<span class="hljs-comment"># 第二种</span><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:    tf.global_variables_initializer().run()    print(sess.run(result))</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>tensorflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>目标检测方法总结</title>
    <link href="/2019/05/15/object_detection/"/>
    <url>/2019/05/15/object_detection/</url>
    
    <content type="html"><![CDATA[<blockquote><p>这是一篇介绍各个目标检测方法的文章，包含：CNN，R-CNN，Fast R-CNN，Faster R-CNN等目标检测算法。<a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/" target="_blank" rel="noopener">文章原文</a></p></blockquote><a id="more"></a><h2 id="解决一个目标检测任务的一个简单方式（使用深度学习）"><a href="#解决一个目标检测任务的一个简单方式（使用深度学习）" class="headerlink" title="解决一个目标检测任务的一个简单方式（使用深度学习）"></a>解决一个目标检测任务的一个简单方式（使用深度学习）</h2><p>接下来是一个受欢迎的示例阐述一个目标检测算法是如何工作的。在图片中的，从一个人到一个降落伞，已经用一个特定等级的精确值来识别和定位。<br><img src="/assets/object_detection/16.png" srcset="/img/loading.gif" alt="图片"><br>让我们开始最简单的深度学习方法，并且也是使用的最广泛的一个，在图像卷积神经网络或者CNNs中检测目标。<br>我将为你简洁地总结一个CNN内部工作，看看下面图片：<br><img src="/assets/object_detection/17.png" srcset="/img/loading.gif" alt="图片"><br>我传递一个图片给那个网络，然后送到不同的卷积和池化层。最终，我们得到目标的类形式的输出。相当直白，不是嘛？<br>对于每个输入图片，我们得到一个相应的类作为输出。我们可以使用这个技术去检测一个图片中不同目标嘛？是的，我们可以！我们来看看使用一个CNN我们可以怎样解决一个通常的目标检测问题。<br>1.首先，我使用一个图像作为输入<br><img src="/assets/object_detection/18.png" srcset="/img/loading.gif" alt="图片"><br>2.然后，我们划分图像成不同的区域<br><img src="/assets/object_detection/19.png" srcset="/img/loading.gif" alt="图片"><br>3.我们考虑每个区域为单独的图像<br>4.传递所有这些区域（图片）到CNN中并且将它们分成不同的类别<br>5.一旦我们已经划分每个区域为相应的类别，我们可以组合所有这些区域来获取检测到的目标的原始图片<br><img src="/assets/object_detection/20.png" srcset="/img/loading.gif" alt="图片"></p><p>使用这个方法的问题是在图像中的目标可能有不同的纵横比和空间位置。例如，在某些情况下，目标可能覆盖大多数图像，而在其他情况下，目标可能只覆盖图像的一小部分。目标的形状可能也不同（在现实使用案例中发生很多事情）</p><p>由于这些因素，我们需要大量的区域导致了大量的计算时间。所以，为了解决这个并且减少区域的数量，我们可以使用基于区域的CNN，它使用提议方法去选择区域。让我们了解这个基于区域的CNN可以为我们做些什么！</p><h2 id="理解R-CNN（基于区域的卷积神经网络）"><a href="#理解R-CNN（基于区域的卷积神经网络）" class="headerlink" title="理解R-CNN（基于区域的卷积神经网络）"></a>理解R-CNN（基于区域的卷积神经网络）</h2><h3 id="R-CNN的总结"><a href="#R-CNN的总结" class="headerlink" title="R-CNN的总结"></a>R-CNN的总结</h3><p>R-CNN算法在图片中提取出一群框代替了大量区域，并且检查这些框是否包含一些目标。R-CNN使用选择性搜索算法（selective search）去从一个图片中提取出这些框（这些框叫做区域）。</p><p>让我们首先理解什么是选择性搜索和它是怎么样识别不同的区域，四个目标：尺度，颜色，纹理和附件（enclosure），选择性搜索识别这些在图片中的模式，并且基于此提议不同的区域。下面是选择搜索工作的简要概述：</p><ul><li>首先它选择一张图片作为输入;<br><img src="/assets/object_detection/1.png" srcset="/img/loading.gif" alt="图片"></li><li>然后，它生成初始的子分割以至于我们从这个图片中有多个区域<br><img src="/assets/object_detection/2.png" srcset="/img/loading.gif" alt="图片"></li><li>这个技术然后组合相似的区域去形成一个更大的区域（基于颜色类似，纹理类似，大小类似和形状兼容性）<br><img src="/assets/object_detection/3.png" srcset="/img/loading.gif" alt="图片"></li><li>最后，这些区域然后产生最终的目标位置（感兴趣的区域，也就是任务所要检测的目标）</li></ul><p>下面是R-CNN检测目标所遵循步骤的简洁摘要：</p><ul><li><p>首先，我们采用预训练的卷积神经网络（或者自己预训练的卷积神经网络）</p></li><li><p>然后，这个模型是被重新训练的，我们根据需要检测类别的数量来训练网络的最后一层。</p></li><li><p>第三步，对于每一个图像得到感兴趣的区域，然后我们重塑所有这些区域以至于他们能够匹配CNN的输入大小</p></li><li><p>在获得区域后，我们训练SVM（支持向量机）去分类目标和背景。对于每一个类别，我们训练一个二进制SVM模型</p></li><li><p>最后我们训练一个线性回归模型去为图片中每个被识别的图片生成严格的边界框</p></li></ul><p>你可以通过可视化示例更好的了解上述步骤，所以让我们应用一个：</p><ul><li>首先，一个图像被作为输入<br><img src="/assets/object_detection/4.png" srcset="/img/loading.gif" alt="图片"></li><li>然后，我们使用一个提议方法（例如上面说的选择性搜索算法（selective search））去获得感兴趣的区域（Region of Interest，RoI）<br><img src="/assets/object_detection/5.png" srcset="/img/loading.gif" alt="图片"></li><li>然后根据CNN的输入形状要求重塑所有这些区域的形状，并且每个区域（region）是被传递到卷积网络中（ConvNet）<br><img src="/assets/object_detection/6.png" srcset="/img/loading.gif" alt="图片"></li><li>然后，CNN提取每个区域的特征，并且使用SVM（支持向量机）去划分这些区域为不同的类别<br><img src="/assets/object_detection/7.png" srcset="/img/loading.gif" alt="图片"></li><li>最后，使用边界框回归器去预测每个被识别区域的边界框<br><img src="/assets/object_detection/8.png" srcset="/img/loading.gif" alt="图片"><br>简而言之，这就是R-CNN如何帮助我们检测目标。</li></ul><h3 id="R-CNN中存在的问题"><a href="#R-CNN中存在的问题" class="headerlink" title="R-CNN中存在的问题"></a>R-CNN中存在的问题</h3><p>So far（到目前为止），我们已经了解R-CNN在目标检测上是如何有益的，但是这个技术自身也有很大的局限性。下面的步骤导致训练一个R-CNN模型带来的巨大代价并且也是很慢的：</p><ul><li><p>基于选择性搜索算法提取2000个区域</p></li><li><p>为每个图像区域使用CNN提取特征，假设我们有N个图像，那CNN特征数量将有N×2000</p></li><li><p>使用R-CNN进行目标检测的整个过程有三个模型：</p><ol><li><p>用于特征提取的CNN模型</p></li><li><p>用于识别目标的线性SVM（支持向量机）分类器</p></li><li><p>用于接近真实边界框的回归模型</p></li></ol></li></ul><p>所有这些过程结合起来使R-CNN变得很慢，对于每个新的图像进行预测需要大约40-50秒，这本质上使得这个模型显得很笨重并且实际上当面对一个庞大的数据集时，也是不可能去构建的。</p><p>这儿，有个好消息！我们有另一个目标检测技术，它解决我们在R-CNN中看到的限制。</p><h2 id="理解Fast-R-CNN"><a href="#理解Fast-R-CNN" class="headerlink" title="理解Fast R-CNN"></a>理解Fast R-CNN</h2><h3 id="Fast-R-CNN概述"><a href="#Fast-R-CNN概述" class="headerlink" title="Fast R-CNN概述"></a>Fast R-CNN概述</h3><p>通常我们需要采取那些方法去减少R-CNN的计算时间，来代替每张图片运行CNN2000次，使得我们每个图像只运行一次就能够得到所有感兴趣区域（这些区域包含一些目标）</p><p>Ross Girshick，R-CNN作者提出了每张图片仅仅运行CNN一次的观点并且然后找到一个在2000个区域中共享计算的方法。在Fast R-CNN中，我们输送输入图片给CNN，它依次产生卷积特征映射。使用这些映射提取建议区域。然后，我们使用一个RoI池层（RoI pooling layer）去重塑所有被提议区域的形状为一个固定的大小，以至于它能够输送到全连接网络。</p><p>让我们分解成步骤去简化概念：</p><p>1.和前两种技术一样，我们采用一个图片作为输入;</p><p>2.这个图片是被传递到一个ConvNet中依次产生感兴趣区域;</p><p>3.通过应用一个RoI池层来重塑所有这些区域的形状并且作为每个ConvNet的输入，然后，每个区域被传递到全连接网络;</p><p>4.在全连接层网络的首个层是使用一个softmax层来输出类别，和softmax层一起，一个线性回归器也平行使用，来输出预测类的边界框坐标;</p><p>所以，并不是像在R-CNN中使用三个不同的模型，Fast R-CNN使用一个单独的模型去从区域中提取特征，划分他们成不同的类并且同时为被识别的类返回边界框。</p><p>为了进一步细分，我将可视化每个步骤，为解释添加实用角度。</p><ul><li>我们遵循现在众所周知的步骤把一个图片作为输入：<br><img src="/assets/object_detection/9.png" srcset="/img/loading.gif" alt="图片"></li><li>这个图像是被传递到一个ConvNet，并且返回相应的感兴趣区域<br><img src="/assets/object_detection/10.png" srcset="/img/loading.gif" alt="图片"></li><li>然后我们在提取的感兴趣区域应用RoI池层（RoI pooling layer）去确保所有的区域是相同的形状大小<br><img src="/assets/object_detection/11.png" srcset="/img/loading.gif" alt="图片"></li><li>最后，这些区域被传递到一个全连接层网络，对他们进行分类，并且同时使用softmax和线性回归层返回边界框<br><img src="/assets/object_detection/12.png" srcset="/img/loading.gif" alt="图片"><br>这就是Fast R-CNN如何解决R-CNN中的两个主要问题，即（1）每张图片传递一个而不是2000个区域给ConvNet（卷积网络），（2）并且使用一个而不是三个不同的模型去提取特征、分类和生成边界框</li></ul><h3 id="Fast-R-CNN存在的问题"><a href="#Fast-R-CNN存在的问题" class="headerlink" title="Fast R-CNN存在的问题"></a>Fast R-CNN存在的问题</h3><p>但是，即使是Fast R-CNN也存在一定的问题，它也使用选择性搜索算法作为提议方法去发现感兴趣区域，这是慢的并且浪费处理时间。每张图片使用大约2秒去检测目标，和R-CNN相比更好点。但是当我们考虑到大型现实的数据集时，然而即使一个Fast R-CNN也看起来不是如此的快。<br>但是，仍然有另外的目标检测算法胜过Fast R-CNN，对于它的名字你不必感到惊讶。</p><h2 id="理解Faster-R-CNN"><a href="#理解Faster-R-CNN" class="headerlink" title="理解Faster R-CNN"></a>理解Faster R-CNN</h2><h3 id="Faster-R-CNN的概述"><a href="#Faster-R-CNN的概述" class="headerlink" title="Faster R-CNN的概述"></a>Faster R-CNN的概述</h3><p>Faster R-CNN是Fast R-CNN修改的版本，在它们之间主要的不同性是Fast R-CNN使用选择性搜索去产生感兴趣区域，而Faster R-CNN使用区域建议网络（RPN，Regions Proposal Network）算法去产生感兴趣区域。RPN采用图像特征映射作为一个输入并且产生一组目标建议，每一个目标建议都以目标分数作为输出。</p><p>下面是Faster R-CNN方法通常遵循的步骤：</p><ul><li><p>首先，我们采用一个图像作为输入并且传递它到ConvNet，然后对于这个图片产生特征映射。</p></li><li><p>这些特征映射使用区域建议网络（RPN）产生带有目标分数的目标建议</p></li><li><p>这些建议使用RoI池层（RoI pooling layer）来降低所有的建议到相同的大小</p></li><li><p>最后，那些提议是被传递到一个全连接层，在这个全连接层的顶部有一个softmax层和一个线性回归层来分类和输出目标的边界框</p></li></ul><p><img src="/assets/object_detection/13.png" srcset="/img/loading.gif" alt="图片"></p><p>让我们简要解释一下这个区域建议网络是如何确切的工作的。</p><p>首先，Faster R-CNN从CNN中获得特征映射并且传递他们到RPN中。RPN在这些特征映射上使用一个滑动窗口，并且在每个窗口上，它产生k个不同形状和大小的锚框（Anchor boxes）<br><img src="/assets/object_detection/14.png" srcset="/img/loading.gif" alt="图片"></p><p>锚框是固定尺度的边界框，其是被放置在整个图像中，并且有不同的形状和大小。对于每个锚框，RPN预测两件事：</p><ul><li><p>首先是一个锚是一个目标的概率（它没有考虑那个目标属于那个类）</p></li><li><p>其次用于调整锚去更好地适应目标的边界框回归器<br>我们现在有不同形状和大小的边界框，他们被传递到RoI池层。现在，在RPN步骤之后，可能会有没有被分配类的建议（提议），我们可以采用每个建议并对其进行裁剪，以至于每个建议包含一个目标。这也就是RoI池层做的事，它为每个锚提取固定尺寸的特征映射：<br><img src="/assets/object_detection/15.png" srcset="/img/loading.gif" alt="图片"><br>然后这些特征映射是被传递到一个全连接层，这个层包含一个softmax层和一个线性回归层。最终，分类目标并且预测被识别目标的边界框。</p></li></ul><h3 id="Faster-R-CNN中存在的问题"><a href="#Faster-R-CNN中存在的问题" class="headerlink" title="Faster R-CNN中存在的问题"></a>Faster R-CNN中存在的问题</h3><p>到目前为至，我们讨论的所有目标检测算法都使用区域去识别目标。这个网络不会不会一次查看完整的图片，而是依次关注图像中某个部分，这也就是创造了两个复杂性：</p><ul><li><p>该算法需要多次通过单个图像去提取所有目标</p></li><li><p>由于不同的系统一个接一个地工作，系统的性能进一步地取决于先前系统是如何执行的</p></li></ul><h2 id="以上算法的总结"><a href="#以上算法的总结" class="headerlink" title="以上算法的总结"></a>以上算法的总结</h2><p>对于我们在这篇文章中讨论的算法，下面的表格是一个很好的总结。我建议下次你正在进行目标检测挑战时保持这个方便！</p><table><thead><tr><th>算法</th><th align="left">特点</th><th align="left">预测时间/图片</th><th align="left">局限性</th></tr></thead><tbody><tr><td>CNN</td><td align="left">划分图片成多个区域并且然后分类每个区域成不同类别</td><td align="left">-</td><td align="left">需要很多区域去预测精确度并且因此很高的计算时间</td></tr><tr><td>RCNN</td><td align="left">选择selectvie search去产生区域，从每个图片提取大约2000区域</td><td align="left">40-50秒</td><td align="left">每个区域分别传递给CNN的计算时间长 它还使用了三种不同模型进行预测</td></tr><tr><td>Fast RCNN</td><td align="left">每个图片传递给CNN仅仅一次并且提取出特征映射 这些特征使用selective search去产生预测  把RCNN中使用的所有三个模型组合在一起</td><td align="left">2秒</td><td align="left">selective search 是慢的并且因此计算时间仍然很高</td></tr><tr><td>Faster RCNN</td><td align="left">使用RPN（Region Proposal Network）替代Selective Search方法使得算法更快</td><td align="left">0.2秒</td><td align="left">目标提议需要时间，并且由于不同的系统一个接一个地工作，系统的性能取决于先前系统的执行方式</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>总结机器学习相关知识与方法</title>
    <link href="/2019/04/01/learning_means/"/>
    <url>/2019/04/01/learning_means/</url>
    
    <content type="html"><![CDATA[<h2 id="学习机器学习的误区"><a href="#学习机器学习的误区" class="headerlink" title="学习机器学习的误区"></a>学习机器学习的误区</h2><p>以下三点是利用Python进行机器学习的误区，应该尽量避免。当然，这些会使你很快了解机器学习的知识，但是不知如何利用机器学习来解决现实中遇到的问题。</p><ul><li>必须非常熟悉Python的语法和擅长Python的编程</li><li>非常深入地学习和理解scikit-learn中使用的机器学习的理论和算法</li><li>避免或者很少参与完成项目，除机器学习之外的部分</li></ul><h2 id="学习机器学习的原则"><a href="#学习机器学习的原则" class="headerlink" title="学习机器学习的原则"></a>学习机器学习的原则</h2><ul><li><strong>学习机器学习是一段旅程。</strong> 需要明白自己具备的技能、目前所掌握的知识，以及明确要达到的目标。</li><li><strong>创建半正式的工作产品。</strong> 以博客文章、技术报告和代码存储的形式记下学习和发现的内容，快速的为自己和他人提供一系列可以展现的技能、知识以及反思。</li><li><strong>实时学习。</strong> 不能仅在需要的时候才学习复杂的主题，例如，应该实时学习足够的概率和线性代数知识来帮助理解正在处理的算法。</li><li><strong>利用现有的技能。</strong> 如果可以编码，那么通过实现算法来理解他们，而不是研究数学理论。使用自己熟悉的编程语言，让自己专注于正在学习的一件事情上，不要同时学习一种新的语言、工具或者类库，这样会使学习过程复杂化。</li><li><strong>掌握是理想。</strong> 掌握机器学习需要持续不断的学习。也许会永远不可能实现掌握机器学习的目标，只能持续不断的学习和改进所掌握的知识。<h2 id="学习机器学习的技巧"><a href="#学习机器学习的技巧" class="headerlink" title="学习机器学习的技巧"></a>学习机器学习的技巧</h2></li><li>启动一个可以在一个小时内完成的小项目</li><li>通过每周完成一个小项目来保持学习势头，并建立积累自己的项目工作区</li><li>在微博、微信、Github等社交工具上分享自己的成果</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录学习卷积网络的问题</title>
    <link href="/2019/04/01/problems/"/>
    <url>/2019/04/01/problems/</url>
    
    <content type="html"><![CDATA[<h2 id="terminate-called-after-throwing-an-instance-of-‘std-bad-alloc’-what-std-bad-alloc-Aborted-core-dumped"><a href="#terminate-called-after-throwing-an-instance-of-‘std-bad-alloc’-what-std-bad-alloc-Aborted-core-dumped" class="headerlink" title="terminate called after throwing an instance of ‘std::bad_alloc’ what(): std::bad_alloc Aborted (core dumped)"></a>terminate called after throwing an instance of ‘std::bad_alloc’ what(): std::bad_alloc Aborted (core dumped)</h2><p>在基于卷积神经网络训练mnist数据集时，设置的batch的值是50，当训练到一万九千多次时发生这种情况。主要原因是由于内存不足，可以尝试减少batch的值，再重新训练。</p><h2 id="AttributeError-module-‘tensorflow-api-v1-train’-has-no-attribute-‘saver’"><a href="#AttributeError-module-‘tensorflow-api-v1-train’-has-no-attribute-‘saver’" class="headerlink" title="AttributeError: module ‘tensorflow._api.v1.train’ has no attribute ‘saver’"></a>AttributeError: module ‘tensorflow._api.v1.train’ has no attribute ‘saver’</h2><p>问题描述：<br>Traceback (most recent call last):<br>File “/home/xiaonan/python_workspace/tensorflow/tensorflow_learning/variables.py”, line 14, in <module><br>    saver = tf.train.saver()<br>AttributeError: module ‘tensorflow._api.v1.train’ has no attribute ‘saver’</module></p><pre><code class="hljs undefined">主要原因是tensorflow在1.0之后已经修改这段代码，将saver()函数修改成类，类需要大写。saver = tf.train().Saver()</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>problem</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>情思悠悠</title>
    <link href="/2018/07/23/love/"/>
    <url>/2018/07/23/love/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在网上看到一个好的鞭策男人的语录，借鉴别人的语录来鞭策自己。让自己更加沉稳，面对困难能够迎刃而解。有句话这样说，一个人的成熟程度，与其情商是成正比，一个人成事的概率也与其情商是成正比。</p></blockquote><p><em>做为一个男人该有的约束</em></p><a id="more"></a><h3 id="一、沉稳"><a href="#一、沉稳" class="headerlink" title="一、沉稳"></a>一、沉稳</h3><p>（1）不要随便显露你的情绪。<br>（2）不要逢人就诉说你的困难和遭遇。<br>（3）在征询别人的意见之前，自己先思考，但不要先讲。<br>（4）不要一有机会就唠叨你的不满。<br>（5）重要的决定尽量有别人商量，最好隔一天再发布。<br>（6）讲话不要有任何的慌张，走路也是。<br>（7）自信是好，但是别忽略任何人的想法。<br>（8）人无高低，不要一副拽拽的样子，对人对事，别忘了礼貌。你没有比任何人优秀。 </p><h3 id="二、细心"><a href="#二、细心" class="headerlink" title="二、细心"></a>二、细心</h3><p>（1）对身边发生的事情，常思考它们的因果关系。<br>（2）对做不到位的问题，要发掘它们的根本症结。<br>（3）对习以为常的做事方法，要有改进或优化的建议。<br>（4）做什么事情都要养成有条不紊和井然有序的习惯。<br>（5）经常去找几个别人看不出来的毛病或弊端。<br>（6）自己要随时随地对有所不足的地方补位。 </p><h3 id="三、胆识"><a href="#三、胆识" class="headerlink" title="三、胆识"></a>三、胆识</h3><p>（1）不要常用缺乏自信的词句。<br>（2）不要常常反悔，轻易推翻已经决定的事。<br>（3）在众人争执不休时，不要没有主见。<br>（4）整体氛围低落时，你要乐观、阳光。<br>（5）做任何事情都要用心，因为有人在看着你。<br>（6）事情不顺的时候，歇口气，重新寻找突破口，就结束也要干净利落。 </p><h3 id="四、大度"><a href="#四、大度" class="headerlink" title="四、大度"></a>四、大度</h3><p>（1）不要刻意把有可能是伙伴的人变成对手。<br>（2）对别人的小过失、小错误不要斤斤计较。<br>（3）在金钱上要大方，学习三施（财施、法施、无畏施）。<br>（4）不要有权力的傲慢和知识的偏见。<br>（5）任何成果和成就都应和别人分享。 </p><h3 id="五、诚信"><a href="#五、诚信" class="headerlink" title="五、诚信"></a>五、诚信</h3><p>（1）做不到的事情不要说，说了就努力做到。<br>（2）虚的口号或标语不要常挂嘴上。<br>（3）停止一切“不道德”的手段。<br>（4）耍弄小聪明，要不得！ </p><h3 id="六、担当"><a href="#六、担当" class="headerlink" title="六、担当"></a>六、担当</h3><p>（1）检讨任何过失的时候，先从自身或自己人开始反省。<br>（2）事情结束后，先审查过错，再列述功劳。<br>（3）一个计划，要统筹全局，规划未来。<br>（4）勇于承担责任所造成的损失。 </p><h3 id="七、内涵"><a href="#七、内涵" class="headerlink" title="七、内涵"></a>七、内涵</h3><p>（1）学习各方面的知识，虚心观察周围的事物。眼界宽阔。<br>（2）了解自己，培养属于自己的审美观。<br>（3）笑对生活。懒惰要不得。培养健康的生活习惯。<br>（4）不要盲目的做任何事。要有目标。<br>（5）不仅仅只关注内在美，外在美也很重要。<br>（6）不要整天的对着电脑，玩着无聊的东西。<br>（7）理智的判断，学会控制情绪。</p>]]></content>
    
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux常见命令汇总</title>
    <link href="/2018/07/22/linux/"/>
    <url>/2018/07/22/linux/</url>
    
    <content type="html"><![CDATA[<blockquote><p>汇总在使用ubuntu时常用到的linux命令</p></blockquote><a id="more"></a><h1 id="1-tar、zip打包解压常见命令"><a href="#1-tar、zip打包解压常见命令" class="headerlink" title="1.tar、zip打包解压常见命令"></a>1.tar、zip打包解压常见命令</h1><p>-c: 建立压缩档案<br>-x：解压<br>-t：查看内容<br>-r：向压缩归档文件末尾追加文件<br>-u：更新原压缩包中的文件</p><p>这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。</p><p>-z：有gzip属性的<br>-j：有bz2属性的<br>-Z：有compress属性的<br>-v：显示所有过程<br>-O：将文件解开到标准输出</p><p>下面的参数-f是必须的</p><p>-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。</p><p> tar -cf all.tar *.jpg<br>这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。</p><p> tar -rf all.tar *.gif<br>这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。</p><p> tar -uf all.tar logo.gif<br>这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。</p><p> tar -tf all.tar<br>这条命令是列出all.tar包中所有文件，-t是列出文件的意思</p><p> tar -xf all.tar<br>这条命令是解出all.tar包中所有文件，-t是解开的意思</p><h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h2><p>tar -cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg </p><p>tar -czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</p><p> tar -cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2</p><p>tar -cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z</p><p>rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux</p><p>zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux</p><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><p>tar -xvf file.tar //解压 tar包</p><p>tar -xzvf file.tar.gz //解压tar.gz</p><p>tar -xjvf file.tar.bz2   //解压 tar.bz2</p><p>tar -xZvf file.tar.Z   //解压tar.Z</p><p>unrar e file.rar //解压rar</p><p>unzip file.zip //解压zip</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1、*.tar 用 tar -xvf 解压</p><p>2、*.gz 用 gzip -d或者gunzip 解压</p><p>3、<em>.tar.gz和</em>.tgz 用 tar -xzf 解压</p><p>4、*.bz2 用 bzip2 -d或者用bunzip2 解压</p><p>5、*.tar.bz2用tar -xjf 解压</p><p>6、*.Z 用 uncompress 解压</p><p>7、*.tar.Z 用tar -xZf 解压</p><p>8、*.rar 用 unrar e解压</p><p>9、*.zip 用 unzip 解压</p><p><em>tar解压jdk到指定文件夹：</em></p><pre><code class="hljs undefined">tar -xzvf jdk-8u131-linux-x64.tar.gz -C /usr/local/java</code></pre><p><em>zip解压文件到指定文件夹：</em></p><pre><code class="hljs undefined">unzip 文件.zip -d /文件夹</code></pre><h2 id="2-无法访问windows系统磁盘"><a href="#2-无法访问windows系统磁盘" class="headerlink" title="2.无法访问windows系统磁盘"></a>2.无法访问windows系统磁盘</h2><blockquote><p>causes:(首先我的电脑是双系统，这也只有双系统的情况才会发生。)<br>应该上一次使用win系统使电脑睡眠，没有完全关机,（应该是非正常关机，要解决的话可以再进一次win系统，正常关机。）这次开机进入ubuntu就出现这种情况。</p></blockquote><p><strong>解决方法：</strong><br><em>a.在终端输入如下命令，查看分区挂载情况</em></p><pre><code class="hljs undefined">sudo fdisk -l</code></pre><p>如图所示：<br><img src="/assets/linux/disk1.png" srcset="/img/loading.gif" alt="分区挂载情况"><br><em>b.修复挂载错误的相应的分区,如提示中的/dev/sda5，输入：</em></p><pre><code class="hljs undefined">sudo ntfsfix /dev/sda5</code></pre><p>这样就修复成功:smiley::smiley:：<br><img src="/assets/linux/disk2.png" srcset="/img/loading.gif" alt="修复成功"></p><h2 id="3-复制文件-夹-和移动文件-夹）"><a href="#3-复制文件-夹-和移动文件-夹）" class="headerlink" title="3.复制文件(夹)和移动文件(夹）"></a>3.复制文件(夹)和移动文件(夹）</h2><blockquote><p>复制、移动、删除的操作命令：cp、mv、rm</p></blockquote><p>一、文件复制命令操作（cp）</p><pre><code class="hljs undefined">命令格式：cp [-adfilprsu] 源文件(source) 目标文件(destination)cp [option] source1 source2 source3 ... directory</code></pre><p>参数说明：<br>-a:是指archive的意思，也说是指复制所有的目录<br>-d:若源文件为连接文件(link file)，则复制连接文件属性而非文件本身<br>-f:强制(force)，若有重复或其它疑问时，不会询问用户，而强制复制<br>-i:若目标文件(destination)已存在，在覆盖时会先询问是否真的操作<br>-l:建立硬连接(hard link)的连接文件，而非复制文件本身<br>-p:与文件的属性一起复制，而非使用默认属性<br>-r:递归复制，用于目录的复制操作<br>-s:复制成符号连接文件(symbolic link)，即“快捷方式”文件<br>-u:若目标文件比源文件旧，更新目标文件 </p><p>如将/test1目录下的file1复制到/test3目录，并将文件名改为file2,可输入以下命令：</p><pre><code class="hljs undefined">cp /test1/file1 /test3/file2</code></pre><p>二、文件移动命令操作（mv）</p><pre><code class="hljs undefined">命令格式：mv [-fiv] source destination</code></pre><p>参数说明：<br>-f:force，强制直接移动而不询问<br>-i:若目标文件(destination)已经存在，就会询问是否覆盖<br>-u:若目标文件已经存在，且源文件比较新，才会更新</p><p>如将/test1目录下的file1复制到/test3 目录，并将文件名改为file2,可输入以下命令：</p><pre><code class="hljs undefined">mv /test1/file1 /test3/file2</code></pre><p>三、文件删除命令操作（rm）</p><pre><code class="hljs undefined">命令格式：rm [fir] 文件或目录</code></pre><p>参数说明：<br>-f:强制删除<br>-i:交互模式，在删除前询问用户是否操作<br>-r:递归删除，常用在目录的删除</p><p>如删除/test目录下的file1文件，可以输入以下命令：</p><pre><code class="hljs undefined">rm -i /test/file1</code></pre><h2 id="使用apt-get方法出现的错误，由于上次使用时未正常结束（强制杀死终端），出现再次使用无法再次使用"><a href="#使用apt-get方法出现的错误，由于上次使用时未正常结束（强制杀死终端），出现再次使用无法再次使用" class="headerlink" title="使用apt-get方法出现的错误，由于上次使用时未正常结束（强制杀死终端），出现再次使用无法再次使用"></a>使用apt-get方法出现的错误，由于上次使用时未正常结束（强制杀死终端），出现再次使用无法再次使用</h2><p>如标题所示发生的错误如下所示：<br><img src="/assets/linux/error1.png" srcset="/img/loading.gif" alt="apt-get再次使用错误"><br>解决代码：</p><pre><code class="hljs undefined">强制解锁命令：sudo rm /var/cache/apt/archives/locksudo rm /var/lib/dpkg/lock</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>佩恩六道</title>
    <link href="/2018/07/21/huoyin/"/>
    <url>/2018/07/21/huoyin/</url>
    
    <content type="html"><![CDATA[<p><img src="/assets/huoyinImg/pn1.jpg" srcset="/img/loading.gif" alt="火影忍者-佩恩">     </p><blockquote><p>感受痛苦吧，体验痛苦吧，接受痛苦吧，了解痛苦吧。不知道痛苦的人是不会知道什么是和平。     </p></blockquote><p><em>—— 《火影忍者》 佩恩六道语录</em></p><a id="more"></a><h2 id="痛苦"><a href="#痛苦" class="headerlink" title="痛苦"></a><strong>痛苦</strong></h2><p><img src="/assets/huoyinImg/pn2.jpg" srcset="/img/loading.gif" alt="火影忍者-佩恩"></p><p>这里死了太多的人，他们的痛苦使我成长。无知愚昧的孩童也只有知道痛苦后才能长大成人。</p><h2 id="正义"><a href="#正义" class="headerlink" title="正义"></a><strong>正义</strong></h2><p><img src="/assets/huoyinImg/pn3.jpg" srcset="/img/loading.gif" alt="火影忍者-佩恩"></p><p>你为了你的正义，我为了我的正义，我们都是被卷进以正义为名的复仇漩涡中的普通人而已。可是，如果复仇以正义为名，那么这样的正义会孕育新的复仇，冤冤相报何时了。而此刻，我们只是活在这样的漩涡中，了解过去、预测未来。所有的这一切，都是历史的一部分。</p><h2 id="神的使命"><a href="#神的使命" class="headerlink" title="神的使命"></a><strong>神的使命</strong></h2><p><img src="/assets/huoyinImg/pn4.jpg" srcset="/img/loading.gif" alt="火影忍者-佩恩">  </p><p>我要在这战火纷飞的俗世中打上停战的休止符，这就是神的使命。国国相战中，怎样才能迅速制止那战争呢？只要把禁术武器参战各国就行了，持有这武器的人一定会使用它的力量。数以千计的人瞬间死光，任何人都会感到恐怖的！人，国家，全世界，就都知道痛苦了。那种恐惧心会产生抑制力，从此再无战争。可以说现在这世界正在向着安定和平的方向成长。痛会让世界成长就像我以前样，要让这世界成长，思想，前进，需要神的说明。这世界还只是孩童，要让世界成长就要让他知道什么叫痛苦。</p><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a><strong>理解</strong></h2><p><img src="/assets/huoyinImg/pn5.jpg" srcset="/img/loading.gif" alt="火影忍者-佩恩"></p><p>曾迫切想与一个人好好聊聊，不仅是寒暄，而是真正的交流，可发现彼此并不能理解。若不知晓相同的痛楚，就无法真正理解他人，而且就算能够理解，也不可能相互体谅，这就是不变的道理。</p><p>其他语录：</p><blockquote><p>（1）你看见树，却未看见森林。<br>（2）当你们试图去寻找死的意义……能找到的……只有痛苦…和不知道归向何方的憎恨…<br>（3）事出总是突然的，而理由则是后来加上去的<br>（4）知道什么叫历史吗?生长于真相之下，明白过去，预感未来，知道那就叫历史。          </p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>动漫</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
